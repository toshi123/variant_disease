{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beT4z2lvLE_h"
   },
   "source": [
    "# コードの動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqbPQ9s1Df7w"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = open(\"/content/drive/MyDrive/ProteinAnalysis/humsavar_noheader.txt\")\n",
    "amino_all = []\n",
    "dis_pol = []\n",
    "for line in data:\n",
    "  elements = line.rstrip().split() \n",
    "  amino_all.append(elements[3])\n",
    "  dis_pol.append(elements[4])\n",
    "amino_before = [s[2:5] for s in amino_all]\n",
    "amino_after = [s[-3:] for s in amino_all]\n",
    "amino_pattern = []\n",
    "\n",
    "i=0\n",
    "#for i in range(0, amino_count): #文字列よりリストで表したほうが好都合であるため\n",
    "  #sub_list = []\n",
    "  # このforいらないのでは？\n",
    "  #for j in range(1):\n",
    "    #sub_list.append(amino_before[i])\n",
    "    #sub_list.append(amino_after[i])\n",
    "    #sub_list.append(dis_pol[i])\n",
    "  #amino_pattern.append(sub_list)\n",
    "  #d = amino_before[i] + \" : \" + amino_after[i] + \" : \" + dis_pol[i]\n",
    "  #amino_pattern.append(d)\n",
    "  # このiを増やしてるのはなぜ？ iはrange関数で順番に与えられるからあってもなくても同じになるはず\n",
    "  #すみません単純に上のwhile文からコピーしてきてミスってました\n",
    "#print(len(amino_pattern_2)) #文字列の際と同じ数であることを確認済\n",
    "\n",
    "amino_pattern_2 = amino_pattern\n",
    "\n",
    "\n",
    "# 上と同じことをするならzipを用いるとすっきり書けるよ\n",
    "# zipの使い方： https://note.nkmk.me/python-zip-usage-for/\n",
    "#\n",
    "for before, after, pol in zip(amino_before, amino_after, dis_pol):\n",
    "   amino_pattern.append([before, after, pol])\n",
    "\n",
    "\n",
    "#def get_unique_list(seq):\n",
    "    #seen = []\n",
    "    #return [x for x in seq if x not in seen and not seen.append(x)] #https://stackoverflow.com/questions/480214/how-do-you-remove-duplicates-from-a-list-whilst-preserving-order\n",
    "\n",
    "## つじコメント 2022/08/02 8:49\n",
    "# ここが問題だと思います。\n",
    "# amino_patternにいろいろな変異と疾患になる情報が入っていて、\n",
    "# その組み合わせの重複をここで捨ててしまっているので少なくなっています。\n",
    "# アミノ酸の変化だけではなく、どの遺伝子（タンパク質）のどこで変位が発生したか\n",
    "# というファクタが重要なので、アミノ酸の変化が同じでも同じだと扱わない方がいいです。\n",
    "\n",
    "#print(len(get_unique_list(amino_pattern))) #文字列の際と同じ数であることを確認済\n",
    "#amino_pattern_2 = get_unique_list(amino_pattern)\n",
    "#print(amino_pattern_2) #重複なし\n",
    "\n",
    "phobic = [\"Ile\", \"Val\", \"Leu\", \"Phe\", \"Met\"]\n",
    "philic = [\"Ala\", \"Thr\", \"Ser\", \"Trp\", \"Tyr\", \"His\", \"Gln\", \"Asn\", \"Glu\", \"Asp\", \"Lys\", \"Arg\"]\n",
    "extra = [\"Cys\", \"Gly\", \"Pro\"]\n",
    "\n",
    "before_phobic=[]\n",
    "#h=0\n",
    "#for h in range(len(phobic)):\n",
    "  #for i in range(len(amino_pattern_2)):\n",
    "    #if phobic[h] in amino_pattern_2[i][0]:\n",
    "      #before_phobic.append(i)\n",
    "#print(\"訂正前\"+sorted(before_phobic)) #変異前が疎水性のアミノ酸である変異の番号\n",
    "\n",
    "#訂正ver\n",
    "for i in range(len(amino_pattern_2)):\n",
    "  if amino_pattern_2[i][0] in phobic:\n",
    "    before_phobic.append(i)\n",
    "#print(\"変異前が疎水性のアミノ酸\",sorted(before_phobic))\n",
    "\n",
    "before_extra =[]\n",
    "for i in range(len(amino_pattern_2)):\n",
    "  if amino_pattern_2[i][0] in extra:\n",
    "    before_extra.append(i)\n",
    "#print(\"変異前がextraのアミノ酸\",sorted(before_extra))\n",
    "\n",
    "after_extra =[]\n",
    "for i in range(len(amino_pattern_2)):\n",
    "  if amino_pattern_2[i][1] in extra:\n",
    "    after_extra.append(i)\n",
    "#print(\"変異前がextraのアミノ酸\",sorted(after_extra))\n",
    "\n",
    "# リスト内にその文字列があるかどうか確認するためにはfor回す必要ないです。\n",
    "# if amino_pattern_2[i][0] in phobic:\n",
    "# とかくと、amino_pattern_2[i][0]に入ってる文字列がリストphobicにあるかどうか判定できる\n",
    "# 参考：https://www.javadrive.jp/python/list/index10.html\n",
    "#amino_pattern_2[i][0]のiを回さないといけなかったので一つは残して大丈夫でしょうか\n",
    "\n",
    "\n",
    "# はい！ そっちのforは残さないとだめですね。\n",
    "# 以下のように書くとリストの中身とりだしてforで回せるよ（知ってるかも）\n",
    "# for amino in amino_pattern_2:\n",
    "#   if amino[0] in phobic:\n",
    "#\n",
    "# このaminoという変数になにが入っているのかとかは説明しないと分かりづらいかも\n",
    "# 簡単に言うと多次元リストはリストの中身にリストが入っている状態なので、\n",
    "# amino_pattern_2 というリストの成分はリストになります。\n",
    "# そのリストを amino という変数に格納しているので、普通にリストとして使えるというわけです。\n",
    "#\n",
    "# i がほしいときは enumerate を使うと何番目かも取れます\n",
    "# 参考サイト：https://note.nkmk.me/python-enumerate-start/\n",
    "#\n",
    "# for i, amino in enumerate(amino_pattern_2):\n",
    "#   if amino[0] in phobic:\n",
    "#     before_phobic.append[i]\n",
    "\n",
    "#知らなかったです！勉強します！\n",
    "\n",
    "# プログラミングはだれかのコードで便利そうな書き方してたらパクるのが一番の勉強なので、\n",
    "# やりたいことがあったら検索してコードを拝借しましょう！\n",
    "\n",
    "\n",
    "after_phobic=[]\n",
    "#h=0\n",
    "#for h in range(len(phobic)):\n",
    "  #for i in range(len(amino_pattern_2)):\n",
    "   #if phobic[h] in amino_pattern_2[i][1]:\n",
    "      #after_phobic.append(i)\n",
    "\n",
    "for i in range(len(amino_pattern_2)):\n",
    "  if amino_pattern_2[i][1] in phobic:\n",
    "    after_phobic.append(i)\n",
    "#print(\"①変異後が疎水性のアミノ酸\",sorted(after_phobic)) #変異後が疎水性のアミノ酸である変異の番号\n",
    "\n",
    "f=[]\n",
    "for i, name in enumerate(amino_pattern_2):\n",
    "  f.append(i)\n",
    "  f.append(name)\n",
    "#print(f)\n",
    "\n",
    "before_philic=[]\n",
    "h=0\n",
    "for i in range(len(amino_pattern_2)):\n",
    "  if amino_pattern_2[i][0] in philic:\n",
    "    before_philic.append(i)\n",
    "#print(\"変異前が親水性のアミノ酸\",sorted(before_philic)) #変異前が親水性のアミノ酸である変異の番号\n",
    "\n",
    "after_philic=[]\n",
    "for i in range(len(amino_pattern_2)):\n",
    "  if amino_pattern_2[i][1] in philic:\n",
    "    after_philic.append(i)\n",
    "#print(\"変異後が親水性のアミノ酸\",sorted(after_philic)) #変異後が親水性のアミノ酸である変異の番号\n",
    "\n",
    "#print(amino_pattern_2)\n",
    "#0を例に見るとHisとArgはどちらも親水性に分類されており、「変異前が親水性」「変異後が親水性」の二つに0と書いてあるから同じ意味になる、はず。\n",
    "#出力したリストの番号を要素の取り出しにそのまま使えるはず\n",
    "\n",
    "# つじコメント 2022/08/01\n",
    "# ここの set で情報が失われているのでは？\n",
    "before_phobic = set(before_phobic)\n",
    "after_phobic = set(after_phobic)\n",
    "before_philic = set(before_philic)\n",
    "after_philic = set(after_philic)\n",
    "after_extra = set(after_extra)\n",
    "before_extra = set(before_extra)\n",
    "\n",
    "\n",
    "phobic_phobic = sorted(before_phobic & after_phobic)\n",
    "#print(\"疎水性→疎水性\",phobic_phobic) #疎水性→疎水性\n",
    "#print(len(phobic_phobic))\n",
    "\n",
    "phobic_philic = sorted(before_phobic & after_philic)\n",
    "#print(\"疎水性→親水性\",phobic_philic) #疎水性→親水性\n",
    "#print(len(phobic_philic))\n",
    "\n",
    "philic_phobic = sorted(before_philic & after_phobic)\n",
    "#print(\"親水性→疎水性\",philic_phobic) #親水性→疎水性\n",
    "#print(len(philic_phobic))\n",
    "\n",
    "philic_philic = sorted(before_philic & after_philic)\n",
    "#print(\"親水性→親水性\",philic_philic) #親水性→親水性\n",
    "#print(len(philic_philic))\n",
    "\n",
    "extra_phobic = sorted(before_extra & after_phobic)\n",
    "#print(\"extra→疎水性\",extra_phobic) #extra→疎水性\n",
    "#print(len(extra_phobic))\n",
    "\n",
    "extra_philic = sorted(before_extra & after_philic)\n",
    "#print(\"extra→親水性\",extra_philic) #extra→親水性\n",
    "#print(len(extra_philic))\n",
    "\n",
    "phobic_extra = sorted(before_phobic & after_extra)\n",
    "#print(\"疎水性→extra\",phobic_extra) #疎水性→extra\n",
    "#print(len(phobic_extra))\n",
    "\n",
    "philic_extra = sorted(before_philic & after_extra)\n",
    "#print(\"親水性→extra\",philic_extra) #親水性→extra\n",
    "#print(len(philic_extra))\n",
    "\n",
    "extra_extra = sorted(before_extra & after_extra)\n",
    "#print(\"extra→extra\",extra_extra) #extra→extra\n",
    "#print(len(extra_extra))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#以下、上のブロックの153行→215行目と同じ\n",
    "#なんかまだショートカットの余地がありそう\n",
    "def category(d_p_mutation, mutation, d_p, name):\n",
    "  for j in range(len(mutation)):\n",
    "    if d_p in amino_pattern_2[int(mutation[j])][2]:\n",
    "      d_p_mutation.append(mutation[j])\n",
    "  print(name, len(d_p_mutation))\n",
    "\n",
    "dis_phobic_phobic = []\n",
    "dis_phobic_philic = []\n",
    "dis_philic_phobic = []\n",
    "dis_philic_philic = []\n",
    "dis_phobic_extra = []\n",
    "dis_extra_phobic = []\n",
    "dis_philic_extra = []\n",
    "dis_extra_philic = []\n",
    "dis_extra_extra = []\n",
    "\n",
    "pol_phobic_phobic = []\n",
    "pol_phobic_philic = []\n",
    "pol_philic_phobic = [] \n",
    "pol_philic_philic = []\n",
    "pol_phobic_extra = []\n",
    "pol_extra_phobic = []\n",
    "pol_philic_extra = []\n",
    "pol_extra_philic = []\n",
    "pol_extra_extra = []\n",
    "\n",
    "unclass_phobic_phobic = []\n",
    "unclass_phobic_philic = []\n",
    "unclass_philic_phobic = []\n",
    "unclass_philic_philic = []\n",
    "unclass_phobic_extra = []\n",
    "unclass_extra_phobic = []\n",
    "unclass_philic_extra = []\n",
    "unclass_extra_philic = []\n",
    "unclass_extra_extra = []\n",
    "\n",
    "d_pho_pho = category(dis_phobic_phobic, phobic_phobic, \"Disease\", \"疎水性→疎水性→病気\")\n",
    "d_pho_phi = category(dis_phobic_philic, phobic_philic, \"Disease\", \"疎水性→親水性→病気\")\n",
    "d_phi_pho = category(dis_philic_phobic, philic_phobic, \"Disease\", \"親水性→疎水性→病気\")\n",
    "d_phi_phi = category(dis_philic_philic, philic_philic, \"Disease\", \"親水性→親水性→病気\")\n",
    "d_pho_ex = category(dis_phobic_extra, phobic_extra, \"Disease\", \"疎水性→extra→病気\")\n",
    "d_phi_ex = category(dis_philic_extra, philic_extra, \"Disease\", \"親水性→extra→病気\")\n",
    "d_ex_pho = category(dis_extra_phobic, extra_phobic, \"Disease\", \"extra→疎水性→病気\")\n",
    "d_ex_phi = category(dis_extra_philic, extra_philic, \"Disease\", \"extra→親水性→病気\")\n",
    "d_ex_ex = category(dis_extra_extra, extra_extra, \"Disease\", \"extra→extra→病気\")\n",
    "\n",
    "p_pho_pho = category(pol_phobic_phobic, phobic_phobic, \"Polymorphism\", \"疎水性→疎水性→病気じゃない\")\n",
    "p_pho_phi = category(pol_phobic_philic, phobic_philic, \"Polymorphism\", \"疎水性→親水性→病気じゃない\")\n",
    "p_phi_pho = category(pol_philic_phobic, philic_phobic, \"Polymorphism\", \"親水性→疎水性→病気じゃない\")\n",
    "p_phi_phi = category(pol_philic_philic, philic_philic, \"Polymorphism\", \"親水性→親水性→病気じゃない\")\n",
    "p_pho_ex = category(pol_phobic_extra, phobic_extra, \"Polymorphism\", \"疎水性→extra→病気じゃない\")\n",
    "p_phi_ex = category(pol_philic_extra, philic_extra, \"Polymorphism\", \"親水性→extra→病気じゃない\")\n",
    "p_ex_pho = category(pol_extra_phobic, extra_phobic, \"Polymorphism\", \"extra→疎水性→病気じゃない\")\n",
    "p_ex_phi = category(pol_extra_philic, extra_philic, \"Polymorphism\", \"extra→親水性→病気じゃない\")\n",
    "p_ex_ex = category(pol_extra_extra, extra_extra, \"Polymorphism\", \"extra→extra→病気じゃない\")\n",
    "\n",
    "u_pho_pho = category(unclass_phobic_phobic, phobic_phobic, \"Unclassified\", \"疎水性→疎水性→分類なし\")\n",
    "u_pho_phi = category(unclass_phobic_philic, phobic_philic, \"Unclassified\", \"疎水性→親水性→分類なし\")\n",
    "u_phi_pho = category(unclass_philic_phobic, philic_phobic, \"Unclassified\", \"親水性→疎水性→分類なし\")\n",
    "u_phi_phi = category(unclass_philic_philic, philic_philic, \"Unclassified\", \"親水性→親水性→分類なし\")\n",
    "u_pho_ex = category(unclass_phobic_extra, phobic_extra, \"Unclassified\", \"疎水性→extra→分類なし\")\n",
    "u_phi_ex = category(unclass_philic_extra, philic_extra, \"Unclassified\", \"親水性→extra→分類なし\")\n",
    "u_ex_pho = category(unclass_extra_phobic, extra_phobic, \"Unclassified\", \"extra→疎水性→分類なし\")\n",
    "u_ex_phi = category(unclass_extra_philic, extra_philic, \"Unclassified\", \"extra→親水性→分類なし\")\n",
    "u_ex_ex = category(unclass_extra_extra, extra_extra, \"Unclassified\", \"extra→extra→分類なし\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMlczMkJxDLO"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = open(\"/content/drive/MyDrive/ProteinAnalysis/humsavar_noheader.txt\")\n",
    "amino_all = []\n",
    "dis_pol = []\n",
    "for line in data:\n",
    "  elements = line.rstrip().split() \n",
    "  amino_all.append(elements[3])\n",
    "  dis_pol.append(elements[4])\n",
    "amino_before = [s[2:5] for s in amino_all]\n",
    "amino_after = [s[-3:] for s in amino_all]\n",
    "amino_pattern = []\n",
    "\n",
    "i=0\n",
    "\n",
    "for before, after, pol in zip(amino_before, amino_after, dis_pol):\n",
    "   amino_pattern.append([before, after, pol])\n",
    "\n",
    "positive = [\"Arg\", \"Lys\", \"His\"]\n",
    "negative = [\"Asp\", \"Glu\"]\n",
    "philic = [\"Asn\", \"Gln\", \"Ser\", \"Thr\", \"Trp\", \"Tyr\"]\n",
    "phobic = [\"Val\", \"Leu\", \"Ile\", \"Phe\", \"Ala\", \"Met\"]\n",
    "extra = [\"Gly\", \"Pro\", \"Cys\"]\n",
    "\n",
    "total=[]\n",
    "def category(mutation, mutation_place, name):\n",
    "  mutation_place = []\n",
    "  for i in range(len(amino_pattern)):\n",
    "    if amino_pattern[i][0] in mutation:\n",
    "      mutation_place.append(i)\n",
    "  total.append(len(mutation_place))\n",
    "  print(name, len(mutation_place))\n",
    "\n",
    "print(\"分類前全パターン: \", len(amino_pattern)) #全てのパターン数\n",
    "b_po = category(positive, \"before_positive\", \"変異前_positive\")\n",
    "b_ne = category(negative, \"before_negative\", \"変異前_negative\")\n",
    "b_phi = category(philic, \"before_philic\", \"変異前_philic\")\n",
    "b_pho = category(phobic, \"before_phobic\", \"変異前_phobic\")\n",
    "b_ex = category(extra, \"before_extra\", \"変異前_extra\")\n",
    "print(\"分類後全パターン: \", sum(total)) #分類後全パターン数\n",
    "\n",
    "all = positive + negative + philic + phobic + extra\n",
    "for info in amino_pattern:\n",
    "  if info[0] not in all:\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwuym7f7AYX8"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = open(\"/content/drive/MyDrive/ProteinAnalysis/humsavar_noheader.txt\")\n",
    "\n",
    "dis = []\n",
    "notindis = [] \n",
    "e = [] \n",
    "r = []\n",
    "diskekka = []\n",
    "notkekka = []\n",
    "\n",
    "\n",
    "for line in data:\n",
    "  elements = line.rstrip().split()\n",
    "  if \"Disease\" in line: \n",
    "    dis.append(elements)\n",
    "  else:\n",
    "    notindis.append(elements)\n",
    "\n",
    "counter = 0\n",
    "for dis_2 in dis:\n",
    "    # 変異から番号を削除、ついでに先頭の p. も削除\n",
    "    pt = dis_2[3][2:5] + dis_2[3][-3:]\n",
    "    # リストの4番目を直接置き換える\n",
    "    dis_2[3] = pt\n",
    "    if pt == \"CysLys\":\n",
    "        counter += 1\n",
    "\n",
    "    # 最後の疾患名を join して一つの文字列に\n",
    "    diseaseName = \" \".join(dis_2[6:])\n",
    "    # リストの7番目以降を削除\n",
    "    # del という命令を使用。詳しくはこちら https://note.nkmk.me/python-list-clear-pop-remove-del/\n",
    "    del dis_2[6:]\n",
    "    # 繋いで1つの文字列にした疾患名を改めてappend\n",
    "    dis_2.append(diseaseName)\n",
    "\n",
    "print(counter)\n",
    "\n",
    "counter = 0\n",
    "for dis_2 in notindis:\n",
    "    # 変異から番号を削除、ついでに先頭の p. も削除\n",
    "    pt = dis_2[3][2:5] + dis_2[3][-3:]\n",
    "    # リストの4番目を直接置き換える\n",
    "    #dis_2[3] = pt\n",
    "    if pt == \"CysLys\":\n",
    "        counter += 1\n",
    "        print(dis_2)\n",
    "\n",
    "print(counter)\n",
    "\n",
    "\n",
    "# for dis_2 in dis:\n",
    "#   v = dis_2[:6]\n",
    "#   d = dis_2[6:-3]\n",
    "#   s = \" \".join(d).rstrip(\",\")\n",
    "#   p = dis_2[3]\n",
    "#   p1 = p[:5]\n",
    "#   p2 = p[-3:]\n",
    "#   pt = p1 + p2\n",
    "#   f = v[0], v[1], v[2], pt, v[4], v[5], s\n",
    "#   print(v)\n",
    "#   print(d)\n",
    "#   print(f)\n",
    "#   break\n",
    "\n",
    "#   s = \" \".join(d).rstrip(\",\")\n",
    "#   p = dis_2[3]\n",
    "#   p1 = p[:5]\n",
    "#   p2 = p[-3:]\n",
    "#   pt = p1 + p2\n",
    "#   f = v[0], v[1], v[2], pt, v[4], v[5], s\n",
    "#   r.append(list(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcpTz-FjB1h_"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = open(\"/content/drive/MyDrive/ProteinAnalysis/humsavar_noheader.txt\")\n",
    "\n",
    "d = defaultdict(int)\n",
    "\n",
    "for line in data:\n",
    "    ac = line.rstrip().split()[1]\n",
    "    varbefore = line.rstrip().split()[3][2:5]\n",
    "    varafter = line.rstrip().split()[3][-3:]\n",
    "    effect = line.rstrip().split()[4]\n",
    "    # if \"Cardiomyopathy\" in line and varbefore == \"Glu\" and varafter == \"Lys\":\n",
    "    # if \"Hemophilia\" in line and varbefore == \"Glu\" and varafter == \"Lys\":\n",
    "    # if effect == \"Disease\" and varbefore == \"Glu\" and varafter == \"Lys\":\n",
    "    if ac == \"P00451\" and effect == \"Disease\" \\\n",
    "    and (varbefore == \"Glu\" or varbefore == \"Asp\" or varbefore == \"Lys\" or varbefore == \"Arg\" or varbefore == \"His\")\\\n",
    "    and (varafter == \"Glu\" or varafter == \"Asp\" or varafter == \"Lys\" or varafter == \"Arg\" or varafter == \"His\"):\n",
    "        # diseaseName = \" \".join(line.rstrip().split()[6:])\n",
    "        # d[diseaseName] += 1\n",
    "        print(line.rstrip())\n",
    "\n",
    "# for k,v in sorted(d.items(), key=lambda x:x[1], reverse=True):\n",
    "#     if v > 10:\n",
    "#         print(\"{}\\t{}\".format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "no2DhXKVKclW"
   },
   "outputs": [],
   "source": [
    "data = open(\"/content/drive/MyDrive/geneAnalysis/uniprot_sprot_human.dat\")\n",
    "\n",
    "proteins = []\n",
    "for line in data:\n",
    "    if line.startswith(\"ID\"):\n",
    "        info = line.rstrip().split()\n",
    "        id = info[1]\n",
    "    elif line.startswith(\"DR   GO;\"):\n",
    "        info = line.rstrip().split(\"; \")\n",
    "        if info[2].startswith(\"F:\"):\n",
    "            # info[1] （GO:0005829;とか）をコロンでスプリットして、\n",
    "            # その2番目をrstrip()して最後のセミコロンを消す。\n",
    "            # 複数行で書いてももちろん良い。\n",
    "            goid = info[1].split(\":\")[1]\n",
    "            # info[2] （F:cadherin binding;など）の最初の「F:」を切り取ってる\n",
    "            function = info[2][2:]\n",
    "    elif line.startswith(\"//\"): # ここでエントリが終わるので集めた情報を集約\n",
    "        prot = {\"ID\":id, \"GOID\":goid, \"Function\":function}\n",
    "        proteins.append(prot)\n",
    "        print(proteins)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWq73F0sKyJo"
   },
   "source": [
    "# 別の話のやつ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yonIBm5FBeIw"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(int)\n",
    "\n",
    "data = open(\"/content/drive/MyDrive/geneAnalysis/clinvar_pathogenic_missense_on_alphafold.220712.txt\")\n",
    "for line in data:\n",
    "    if line.startswith(\"Uniprot\"):\n",
    "        continue\n",
    "    # UniProt\tPos\tGeneSymbol\tGeneID\tRefSeq\tRefSeqPos\tRSA\tpLDDT\tRSID\tMutation\tClinicalSignificance\tOMIM\tDisease\n",
    "    # Q9NPC4-F1\t187\tA4GALT\t53947\tNP_059132.1\t187\t0.022\t97.23\trs28940572\tp.Gly187Asp\tLikely pathogenic; Affects\t-\t-\n",
    "    entry = line.rstrip().split(\"\\t\")\n",
    "    before = entry[9][2:5]\n",
    "    after = entry[9][-3:]\n",
    "#    d[before+after] += 1\n",
    "    if before == \"Gly\" and after == \"Arg\":\n",
    "        d[entry[12]] += 1\n",
    "\n",
    "for k,v in sorted(d.items(), key=lambda x:x[1], reverse=True):\n",
    "     print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umIf5AfoPA_f",
    "outputId": "b9f778c7-b36e-4838-8d87-08cef542006a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRJWet1HvQMa"
   },
   "outputs": [],
   "source": [
    "# Kyte & Doolittle index of hydrophobicity\n",
    "# J. Mol. Biol. 157:105-132(1982).\n",
    "# \"KyteDoolittle\"\n",
    "kd = {\"A\": 1.8, \"R\": -4.5, \"N\": -3.5, \"D\": -3.5, \"C\": 2.5,\n",
    "      \"Q\": -3.5, \"E\": -3.5, \"G\": -0.4, \"H\": -3.2, \"I\": 4.5,\n",
    "      \"L\": 3.8, \"K\": -3.9, \"M\": 1.9, \"F\": 2.8, \"P\": -1.6,\n",
    "      \"S\": -0.8, \"T\": -0.7, \"W\": -0.9, \"Y\": -1.3, \"V\": 4.2,\n",
    "      \"B\": 0.0, \"J\": 0.0, \"O\": 0.0, \"U\": 0.0, \"X\": 0.0, \"Z\": 0.0,\n",
    "}\n",
    "kd3 = {\"Ala\": 1.8, \"Arg\": -4.5, \"Asn\": -3.5, \"Asp\": -3.5, \"Cys\": 2.5,\n",
    "      \"Gln\": -3.5, \"Glu\": -3.5, \"Gly\": -0.4, \"His\": -3.2, \"Ile\": 4.5,\n",
    "      \"Leu\": 3.8, \"Lys\": -3.9, \"Met\": 1.9, \"Phe\": 2.8, \"Pro\": -1.6,\n",
    "      \"Ser\": -0.8, \"Thr\": -0.7, \"Trp\": -0.9, \"Tyr\": -1.3, \"Val\": 4.2\n",
    "}\n",
    "# volume of amino acid\n",
    "vol = {\n",
    " 'Ala': 67, 'Arg': 148, 'Asp': 96, 'Asn': 91, 'Cys': 86,\n",
    " 'Gln': 114, 'Glu': 109, 'Gly': 48, 'His': 118, 'Ile': 124,\n",
    " 'Leu': 124, 'Lys': 135, 'Met': 124, 'Phe': 135, 'Pro': 90,\n",
    " 'Ser': 73, 'Thr': 93, 'Trp': 163, 'Tyr': 141, 'Val': 105\n",
    "}\n",
    "\n",
    "# Surface accessibility\n",
    "# Vergoten G & Theophanides T, Biomolecular Structure and Dynamics,\n",
    "# pg.138 (1997).\n",
    "# 1 Emini Surface fractional probability\n",
    "em = {\"A\": 0.815, \"R\": 1.475, \"N\": 1.296, \"D\": 1.283, \"C\": 0.394,\n",
    "      \"Q\": 1.348, \"E\": 1.445, \"G\": 0.714, \"H\": 1.180, \"I\": 0.603,\n",
    "      \"L\": 0.603, \"K\": 1.545, \"M\": 0.714, \"F\": 0.695, \"P\": 1.236,\n",
    "      \"S\": 1.115, \"T\": 1.184, \"W\": 0.808, \"Y\": 1.089, \"V\": 0.606}\n",
    "\n",
    "# 2 Janin Interior to surface transfer energy scale\n",
    "ja = {\"A\": 0.28, \"R\": -1.14, \"N\": -0.55, \"D\": -0.52, \"C\": 0.97,\n",
    "      \"Q\": -0.69, \"E\": -1.01, \"G\": 0.43, \"H\": -0.31, \"I\": 0.60,\n",
    "      \"L\": 0.60, \"K\": -1.62, \"M\": 0.43, \"F\": 0.46, \"P\": -0.42,\n",
    "      \"S\": -0.19, \"T\": -0.32, \"W\": 0.29, \"Y\": -0.15, \"V\": 0.60}\n",
    "\n",
    "\n",
    "# A two dimensional dictionary for calculating the instability index.\n",
    "# Guruprasad K., Reddy B.V.B., Pandit M.W. Protein Engineering 4:155-161(1990).\n",
    "# It is based on dipeptide values; therefore, the value for the dipeptide DG\n",
    "# is DIWV['D']['G'].\n",
    "DIWV = {\"A\": {\"A\": 1.0, \"C\": 44.94, \"E\": 1.0, \"D\": -7.49,\n",
    "              \"G\": 1.0, \"F\": 1.0, \"I\": 1.0, \"H\": -7.49,\n",
    "              \"K\": 1.0, \"M\": 1.0, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 1.0, \"P\": 20.26, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": 1.0, \"W\": 1.0, \"V\": 1.0, \"Y\": 1.0},\n",
    "        \"C\": {\"A\": 1.0, \"C\": 1.0, \"E\": 1.0, \"D\": 20.26,\n",
    "              \"G\": 1.0, \"F\": 1.0, \"I\": 1.0, \"H\": 33.60,\n",
    "              \"K\": 1.0, \"M\": 33.60, \"L\": 20.26, \"N\": 1.0,\n",
    "              \"Q\": -6.54, \"P\": 20.26, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": 33.60, \"W\": 24.68, \"V\": -6.54, \"Y\": 1.0},\n",
    "        \"E\": {\"A\": 1.0, \"C\": 44.94, \"E\": 33.60, \"D\": 20.26,\n",
    "              \"G\": 1.0, \"F\": 1.0, \"I\": 20.26, \"H\": -6.54,\n",
    "              \"K\": 1.0, \"M\": 1.0, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 20.26, \"P\": 20.26, \"S\": 20.26, \"R\": 1.0,\n",
    "              \"T\": 1.0, \"W\": -14.03, \"V\": 1.0, \"Y\": 1.0},\n",
    "        \"D\": {\"A\": 1.0, \"C\": 1.0, \"E\": 1.0, \"D\": 1.0,\n",
    "              \"G\": 1.0, \"F\": -6.54, \"I\": 1.0, \"H\": 1.0,\n",
    "              \"K\": -7.49, \"M\": 1.0, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 1.0, \"P\": 1.0, \"S\": 20.26, \"R\": -6.54,\n",
    "              \"T\": -14.03, \"W\": 1.0, \"V\": 1.0, \"Y\": 1.0},\n",
    "        \"G\": {\"A\": -7.49, \"C\": 1.0, \"E\": -6.54, \"D\": 1.0,\n",
    "              \"G\": 13.34, \"F\": 1.0, \"I\": -7.49, \"H\": 1.0,\n",
    "              \"K\": -7.49, \"M\": 1.0, \"L\": 1.0, \"N\": -7.49,\n",
    "              \"Q\": 1.0, \"P\": 1.0, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": -7.49, \"W\": 13.34, \"V\": 1.0, \"Y\": -7.49},\n",
    "        \"F\": {\"A\": 1.0, \"C\": 1.0, \"E\": 1.0, \"D\": 13.34,\n",
    "              \"G\": 1.0, \"F\": 1.0, \"I\": 1.0, \"H\": 1.0,\n",
    "              \"K\": -14.03, \"M\": 1.0, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 1.0, \"P\": 20.26, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": 1.0, \"W\": 1.0, \"V\": 1.0, \"Y\": 33.601},\n",
    "        \"I\": {\"A\": 1.0, \"C\": 1.0, \"E\": 44.94, \"D\": 1.0,\n",
    "              \"G\": 1.0, \"F\": 1.0, \"I\": 1.0, \"H\": 13.34,\n",
    "              \"K\": -7.49, \"M\": 1.0, \"L\": 20.26, \"N\": 1.0,\n",
    "              \"Q\": 1.0, \"P\": -1.88, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": 1.0, \"W\": 1.0, \"V\": -7.49, \"Y\": 1.0},\n",
    "        \"H\": {\"A\": 1.0, \"C\": 1.0, \"E\": 1.0, \"D\": 1.0,\n",
    "              \"G\": -9.37, \"F\": -9.37, \"I\": 44.94, \"H\": 1.0,\n",
    "              \"K\": 24.68, \"M\": 1.0, \"L\": 1.0, \"N\": 24.68,\n",
    "              \"Q\": 1.0, \"P\": -1.88, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": -6.54, \"W\": -1.88, \"V\": 1.0, \"Y\": 44.94},\n",
    "        \"K\": {\"A\": 1.0, \"C\": 1.0, \"E\": 1.0, \"D\": 1.0,\n",
    "              \"G\": -7.49, \"F\": 1.0, \"I\": -7.49, \"H\": 1.0,\n",
    "              \"K\": 1.0, \"M\": 33.60, \"L\": -7.49, \"N\": 1.0,\n",
    "              \"Q\": 24.64, \"P\": -6.54, \"S\": 1.0, \"R\": 33.60,\n",
    "              \"T\": 1.0, \"W\": 1.0, \"V\": -7.49, \"Y\": 1.0},\n",
    "        \"M\": {\"A\": 13.34, \"C\": 1.0, \"E\": 1.0, \"D\": 1.0,\n",
    "              \"G\": 1.0, \"F\": 1.0, \"I\": 1.0, \"H\": 58.28,\n",
    "              \"K\": 1.0, \"M\": -1.88, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": -6.54, \"P\": 44.94, \"S\": 44.94, \"R\": -6.54,\n",
    "              \"T\": -1.88, \"W\": 1.0, \"V\": 1.0, \"Y\": 24.68},\n",
    "        \"L\": {\"A\": 1.0, \"C\": 1.0, \"E\": 1.0, \"D\": 1.0,\n",
    "              \"G\": 1.0, \"F\": 1.0, \"I\": 1.0, \"H\": 1.0,\n",
    "              \"K\": -7.49, \"M\": 1.0, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 33.60, \"P\": 20.26, \"S\": 1.0, \"R\": 20.26,\n",
    "              \"T\": 1.0, \"W\": 24.68, \"V\": 1.0, \"Y\": 1.0},\n",
    "        \"N\": {\"A\": 1.0, \"C\": -1.88, \"E\": 1.0, \"D\": 1.0,\n",
    "              \"G\": -14.03, \"F\": -14.03, \"I\": 44.94, \"H\": 1.0,\n",
    "              \"K\": 24.68, \"M\": 1.0, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": -6.54, \"P\": -1.88, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": -7.49, \"W\": -9.37, \"V\": 1.0, \"Y\": 1.0},\n",
    "        \"Q\": {\"A\": 1.0, \"C\": -6.54, \"E\": 20.26, \"D\": 20.26,\n",
    "              \"G\": 1.0, \"F\": -6.54, \"I\": 1.0, \"H\": 1.0,\n",
    "              \"K\": 1.0, \"M\": 1.0, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 20.26, \"P\": 20.26, \"S\": 44.94, \"R\": 1.0,\n",
    "              \"T\": 1.0, \"W\": 1.0, \"V\": -6.54, \"Y\": -6.54},\n",
    "        \"P\": {\"A\": 20.26, \"C\": -6.54, \"E\": 18.38, \"D\": -6.54,\n",
    "              \"G\": 1.0, \"F\": 20.26, \"I\": 1.0, \"H\": 1.0,\n",
    "              \"K\": 1.0, \"M\": -6.54, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 20.26, \"P\": 20.26, \"S\": 20.26, \"R\": -6.54,\n",
    "              \"T\": 1.0, \"W\": -1.88, \"V\": 20.26, \"Y\": 1.0},\n",
    "        \"S\": {\"A\": 1.0, \"C\": 33.60, \"E\": 20.26, \"D\": 1.0,\n",
    "              \"G\": 1.0, \"F\": 1.0, \"I\": 1.0, \"H\": 1.0,\n",
    "              \"K\": 1.0, \"M\": 1.0, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 20.26, \"P\": 44.94, \"S\": 20.26, \"R\": 20.26,\n",
    "              \"T\": 1.0, \"W\": 1.0, \"V\": 1.0, \"Y\": 1.0},\n",
    "        \"R\": {\"A\": 1.0, \"C\": 1.0, \"E\": 1.0, \"D\": 1.0,\n",
    "              \"G\": -7.49, \"F\": 1.0, \"I\": 1.0, \"H\": 20.26,\n",
    "              \"K\": 1.0, \"M\": 1.0, \"L\": 1.0, \"N\": 13.34,\n",
    "              \"Q\": 20.26, \"P\": 20.26, \"S\": 44.94, \"R\": 58.28,\n",
    "              \"T\": 1.0, \"W\": 58.28, \"V\": 1.0, \"Y\": -6.54},\n",
    "        \"T\": {\"A\": 1.0, \"C\": 1.0, \"E\": 20.26, \"D\": 1.0,\n",
    "              \"G\": -7.49, \"F\": 13.34, \"I\": 1.0, \"H\": 1.0,\n",
    "              \"K\": 1.0, \"M\": 1.0, \"L\": 1.0, \"N\": -14.03,\n",
    "              \"Q\": -6.54, \"P\": 1.0, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": 1.0, \"W\": -14.03, \"V\": 1.0, \"Y\": 1.0},\n",
    "        \"W\": {\"A\": -14.03, \"C\": 1.0, \"E\": 1.0, \"D\": 1.0,\n",
    "              \"G\": -9.37, \"F\": 1.0, \"I\": 1.0, \"H\": 24.68,\n",
    "              \"K\": 1.0, \"M\": 24.68, \"L\": 13.34, \"N\": 13.34,\n",
    "              \"Q\": 1.0, \"P\": 1.0, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": -14.03, \"W\": 1.0, \"V\": -7.49, \"Y\": 1.0},\n",
    "        \"V\": {\"A\": 1.0, \"C\": 1.0, \"E\": 1.0, \"D\": -14.03,\n",
    "              \"G\": -7.49, \"F\": 1.0, \"I\": 1.0, \"H\": 1.0,\n",
    "              \"K\": -1.88, \"M\": 1.0, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 1.0, \"P\": 20.26, \"S\": 1.0, \"R\": 1.0,\n",
    "              \"T\": -7.49, \"W\": 1.0, \"V\": 1.0, \"Y\": -6.54},\n",
    "        \"Y\": {\"A\": 24.68, \"C\": 1.0, \"E\": -6.54, \"D\": 24.68,\n",
    "              \"G\": -7.49, \"F\": 1.0, \"I\": 1.0, \"H\": 13.34,\n",
    "              \"K\": 1.0, \"M\": 44.94, \"L\": 1.0, \"N\": 1.0,\n",
    "              \"Q\": 1.0, \"P\": 13.34, \"S\": 1.0, \"R\": -15.91,\n",
    "              \"T\": -7.49, \"W\": -9.37, \"V\": 1.0, \"Y\": 13.34},\n",
    "        }\n",
    "\n",
    "three2one = {\"Ala\": \"A\", \"Arg\": \"R\", \"Asn\": \"N\", \"Asp\": \"D\", \"Cys\": \"C\",\n",
    "      \"Gln\": \"Q\", \"Glu\": \"E\", \"Gly\": \"G\", \"His\": \"H\", \"Ile\": \"I\",\n",
    "      \"Leu\": \"L\", \"Lys\": \"K\", \"Met\": \"M\", \"Phe\": \"F\", \"Pro\": \"P\",\n",
    "      \"Ser\": \"S\", \"Thr\": \"T\", \"Trp\": \"W\", \"Tyr\": \"Y\", \"Val\": \"V\"\n",
    "}\n",
    "one2three = {\"A\":\"Ala\", \"R\":\"Arg\", \"N\":\"Asn\", \"D\":\"Asp\", \"C\":\"Cys\",\n",
    "      \"Q\":\"Gln\", \"E\":\"Glu\", \"G\":\"Gly\", \"H\":\"His\", \"I\":\"Ile\",\n",
    "      \"L\":\"Leu\", \"K\":\"Lys\", \"M\":\"Met\", \"F\":\"Phe\", \"P\":\"Pro\",\n",
    "      \"S\":\"Ser\", \"T\":\"Thr\", \"W\":\"Trp\", \"Y\":\"Tyr\", \"V\":\"Val\"\n",
    "}\n",
    "\n",
    "aaone = [\"A\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"V\",\"W\",\"Y\",\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUCepixJkfEi",
    "outputId": "e049d18b-4c8a-473e-f981-b0b1b853d746"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "def editChains(chainranges):\n",
    "    regs = defaultdict(list)\n",
    "    for reg in chainranges.split(\",\"):\n",
    "        chain,region = reg.split(\":\")\n",
    "        regs[chain].append(region)\n",
    "    result = {}\n",
    "    for chain,regions in regs.items():\n",
    "        result[chain] = \",\".join(regions)\n",
    "    return result\n",
    "\n",
    "ecodinfo = defaultdict(list)\n",
    "ecod = defaultdict(list)\n",
    "xname = defaultdict(list)\n",
    "for line in open(\"/content/drive/MyDrive/geneAnalysis/ecod.latest.domains20230117.txt\"):\n",
    "    if line.startswith(\"#\"): continue\n",
    "    #uid    ecod_domain_id  manual_rep      f_id    pdb     chain   pdb_range       seqid_range     arch_name       x_name  h_name  t_name  f_name  asm_status      ligand\n",
    "    #000000011       e1htr.1 MANUAL_REP      1.1.1.1 1htr    .       P:1-43,B:1-329  P:1-43,B:1-329  beta barrels    cradle loop barrel      RIFT-related    acid protease   EF00082,EF00710 NOT_DOMAIN_ASSEMBLY     NO_LIGANDS_4A\n",
    "    data = line.rstrip().split(\"\\t\")\n",
    "    pdb = data[4]\n",
    "    chain = data[5]\n",
    "    pdbinfo = pdb+chain\n",
    "    fid = data[3]\n",
    "    pdbrange = data[6]\n",
    "    seqrange = data[7]\n",
    "    archname = data[9]\n",
    "    x = data[10].replace('\"','')\n",
    "    h = data[11].replace('\"','')\n",
    "    t = data[12].replace('\"','')\n",
    "    f = data[13].replace('\"','')\n",
    "    try:\n",
    "        pdbranges = editChains(pdbrange)\n",
    "    except ValueError as e:\n",
    "        print(\"{}\\t{}\".format(pdb, fid))\n",
    "        continue\n",
    "    seqranges = editChains(seqrange)\n",
    "    # pdbranges = pdbrange.split(\",\")\n",
    "    # seqranges = seqrange.split(\",\")\n",
    "    for chain,region in pdbranges.items():\n",
    "        try:\n",
    "            seqregion = seqranges[chain]\n",
    "        except KeyError as e:\n",
    "            print(\"{}\\t{}\".format(pdb, fid))\n",
    "            continue\n",
    "\n",
    "        pdbinfo = pdb+chain\n",
    "        ecodinfo[pdbinfo].append({\"f_id\":fid,\"pdb_range\":region,\"seq_range\":seqregion,\"arch_name\":archname,\"x_name\":x,\"h_name\":h,\"t_name\":t,\"f_name\":f})\n",
    "    # if fid not in ecod[pdbinfo]:\n",
    "    #     ecod[pdbinfo].append(fid)\n",
    "    #     xname[pdbinfo].append(x)\n",
    "\n",
    "# print json.dumps(ecodinfo,indent=4)\n",
    "with open('/content/drive/MyDrive/geneAnalysis/ecod.json', 'w') as f:\n",
    "    json.dump(ecodinfo, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyUC4oGFz1l7"
   },
   "source": [
    "- GOごとに疾患関連変異がどのくらいの割合で存在するか網羅的に計算するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HJgpAkCzzIn"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# jsonファイルの読み込み\n",
    "json_open = open('ac2go.json', 'r')\n",
    "ac2go = json.load(json_open)\n",
    "\n",
    "# 変異と疾患のデータ（humsavar.txt）の読み込み\n",
    "data = open(\"humsavar_noheader.txt\")\n",
    "\n",
    "gogroup = [\"C\",\"F\",\"P\"]\n",
    "dis_term = defaultdict(int)\n",
    "pol_term = defaultdict(int)\n",
    "count = defaultdict(int)\n",
    "count_seq = defaultdict(set)\n",
    "\n",
    "for line in data:\n",
    "    entry = line.rstrip().split()\n",
    "    geneid, ac, varid, varpattern, effect, rsid = entry[:6]\n",
    "\n",
    "    if ac not in ac2go or (effect != \"Disease\" and effect != \"Polymorphism\"): continue\n",
    "    for g in gogroup:\n",
    "        for goterm in ac2go[ac][g]:\n",
    "            gg = g + \":\" + goterm\n",
    "            count[gg] += 1\n",
    "            count_seq[gg].add(ac)\n",
    "            if effect == \"Disease\":\n",
    "                dis_term[gg] += 1\n",
    "            else:\n",
    "                pol_term[gg] += 1\n",
    "\n",
    "# filepath = \"/content/drive/MyDrive/geneAnalysis/goscores.tsv\"\n",
    "dd = {}\n",
    "for g,num in sorted(count.items(), key=lambda x:x[1], reverse=True):\n",
    "    if num < 1000: continue\n",
    "    d = 0 if g not in dis_term else dis_term[g]\n",
    "    p = 0 if g not in pol_term else pol_term[g]\n",
    "    pd = d / (p + d)\n",
    "    num_seq = len(count_seq[g])\n",
    "    # terms = \"{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(g,num,d,p,num_seq,\",\".join(list(count_seq[g])))\n",
    "    terms = \"{}\\t{}\\t{}\\t{}\\t{}\".format(g,num,d,p,num_seq)\n",
    "    dd[terms] = pd\n",
    "    # with open(filepath, mode=\"a\") as f:\n",
    "    #         f.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(g,num,d,p,pd))\n",
    "\n",
    "filepath = \"goscores_sorted_1000_test.tsv\"\n",
    "for t,n in sorted(dd.items(), key=lambda x:x[1], reverse=True):\n",
    "    with open(filepath, mode=\"a\") as f:\n",
    "        f.write(\"{}\\t{:.4f}\\n\".format(t,n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfSGQXDQx44Z"
   },
   "source": [
    "- 差を計算するだけの関数\n",
    "- 移動平均を計算する関数\n",
    "- 細胞内局在位置を大雑把にまとめる関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Bz9Qfl7Ff6K"
   },
   "outputs": [],
   "source": [
    "def calcDiff(index,before,after):\n",
    "    return index[before] - index[after]\n",
    "\n",
    "def calcMovingAverage(values,half_window):\n",
    "    movingave = []\n",
    "    for i in range(len(values)):\n",
    "        localsum = 0\n",
    "        localaa = 0\n",
    "        for j in range(i - half_window, i + half_window + 1):\n",
    "            if j > -1 and j < len(values):\n",
    "                localsum += values[j]\n",
    "                localaa += 1\n",
    "        localave = localsum / localaa\n",
    "        movingave.append(localave)\n",
    "    return movingave\n",
    "\n",
    "def calcAve(index,seq):\n",
    "    sum = 0.0\n",
    "    for aa in seq:\n",
    "        sum += index[aa]\n",
    "    return sum/len(seq)\n",
    "\n",
    "def detectSubCellularLocation(subcell):\n",
    "    sc = subcell.lower()\n",
    "    if \"mitochondri\" in sc:\n",
    "        return \"Mitochondrion\"\n",
    "    elif \"cytoplasm\" in sc:\n",
    "        return \"Cytoplasm\"\n",
    "    elif \"nucle\" in sc:\n",
    "        return \"Nucleus\"\n",
    "    # elif \"golgi\" in sc:\n",
    "    #     return \"Golgi\"\n",
    "    # elif \"endoplasmic\" in sc:\n",
    "    #     return \"ER\"\n",
    "    # elif \"peroxisome\" in sc:\n",
    "    #     return \"Peroxisome\"\n",
    "    # elif \"lysosome\" in sc:\n",
    "    #     return \"Lysosome\"\n",
    "    elif \"membrane\" in sc:\n",
    "        return \"Membrane\"\n",
    "    elif \"secret\" in sc:\n",
    "        return \"Secreted\"\n",
    "    else:\n",
    "        return \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvAt-TkvtQgP"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# jsonファイルの読み込み\n",
    "json_open = open('ac2subcellularlocations.json', 'r')\n",
    "ac2subcellularlocations = json.load(json_open)\n",
    "json_open = open('ac2go.json', 'r')\n",
    "ac2go = json.load(json_open)\n",
    "json_open = open('ac2seq.json', 'r')\n",
    "ac2seq = json.load(json_open)\n",
    "json_open = open('varrelatedis.json', 'r')\n",
    "varscore = json.load(json_open)\n",
    "json_open = open('blosum62.json', 'r')\n",
    "blosum = json.load(json_open)\n",
    "json_open = open('ac2conserved_humsavar.json', 'r')\n",
    "conserved = json.load(json_open)\n",
    "\n",
    "# 変異と疾患のデータ（humsavar.txt）の読み込み\n",
    "data = open(\"humsavar_noheader.txt\")\n",
    "\n",
    "# 書き出すファイル\n",
    "filepath = \"variantdata4cat_verTest_conserved_20231203.tsv\"\n",
    "\n",
    "with open(filepath, mode=\"a\") as f:\n",
    "    f.write(\"AC\\tsub\\tbefore\\tafter\\tposition\\tlength\\tscore\\tconserved_before\\tconserved_after\\tblosum62\\tDIWVscore\\tdiff_hyd\\tdiff_vol\\thyd_7aa\\thyd_11aa\\tem7\\tja7\\teffect\\n\")\n",
    "\n",
    "# 20種のアミノ酸で構成されているかどうか確認するためのリスト\n",
    "checkaa = {\"Ala\", \"Arg\", \"Asn\", \"Asp\", \"Cys\",\n",
    "      \"Gln\", \"Glu\", \"Gly\", \"His\", \"Ile\",\n",
    "      \"Leu\", \"Lys\", \"Met\", \"Phe\", \"Pro\",\n",
    "      \"Ser\", \"Thr\", \"Trp\", \"Tyr\", \"Val\"\n",
    "}\n",
    "\n",
    "for line in data:\n",
    "    entry = line.rstrip().split()\n",
    "    geneid, ac, varid, varpattern, effect, rsid = entry[:6]\n",
    "\n",
    "    if effect == \"Disease\" or effect == \"Polymorphism\":\n",
    "\n",
    "        if ac not in conserved:\n",
    "            continue\n",
    "\n",
    "        before = varpattern[2:5]\n",
    "        after = varpattern[-3:]\n",
    "        position = int(varpattern[5:-3])\n",
    "        if before not in checkaa or after not in checkaa:\n",
    "            continue\n",
    "        \n",
    "        diffhyd = calcDiff(kd3,before,after)\n",
    "        diffvol = calcDiff(vol,before,after)\n",
    "        score = varscore[before][after]\n",
    "        DIWVscore = DIWV[three2one[before]][three2one[after]]\n",
    "        blosum62score = blosum[three2one[before]][three2one[after]]\n",
    "\n",
    "        # 保存性の切り出し\n",
    "        conserved_before = 1.0\n",
    "        conserved_after = 0.0\n",
    "        if str(position-1) in conserved[ac] and three2one[before] in conserved[ac][str(position-1)]:\n",
    "            conserved_before = conserved[ac][str(position-1)][three2one[before]]\n",
    "        if str(position-1) in conserved[ac] and three2one[after] in conserved[ac][str(position-1)]:\n",
    "            conserved_after = conserved[ac][str(position-1)][three2one[after]]\n",
    "\n",
    "        omim = \",\".join(entry[6:])\n",
    "\n",
    "        if ac not in ac2seq or position < 0 or position >= len(ac2seq[ac]):\n",
    "            continue\n",
    "\n",
    "        seq = ac2seq[ac]\n",
    "        aminolength = len(seq)\n",
    "        rel_pos = (position/aminolength)\n",
    "\n",
    "        subcel = \"Nothing\" if ac not in ac2subcellularlocations else ac2subcellularlocations[ac][0]\n",
    "        subcel = detectSubCellularLocation(subcel)\n",
    "        # if subcel != \"Membrane\":\n",
    "        #     continue\n",
    "\n",
    "        hydval = []\n",
    "        emval = []\n",
    "        javal = []\n",
    "        for aa in seq:\n",
    "            if aa not in kd:\n",
    "                continue\n",
    "            hydval.append(kd[aa])\n",
    "            emval.append(em[aa])\n",
    "            javal.append(ja[aa])\n",
    "        hydave7 = calcMovingAverage(hydval,3)\n",
    "        hydave11 = calcMovingAverage(hydval,5)\n",
    "        emave7 = calcMovingAverage(emval,3)\n",
    "        jaave7 = calcMovingAverage(javal,3)\n",
    "        hyd7 = hydave7[position]\n",
    "        hyd11 = hydave11[position]\n",
    "        em7 = emave7[position]\n",
    "        ja7 = jaave7[position]\n",
    "        with open(filepath, mode=\"a\") as f:\n",
    "            f.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".\n",
    "                    format(\n",
    "                        ac,\n",
    "                        subcel,\n",
    "                        before,\n",
    "                        after,\n",
    "                        rel_pos,\n",
    "                        aminolength,\n",
    "                        score,\n",
    "                        conserved_before,\n",
    "                        conserved_after,\n",
    "                        blosum62score,\n",
    "                        DIWVscore,\n",
    "                        diffhyd,\n",
    "                        diffvol,\n",
    "                        hyd7,\n",
    "                        hyd11,\n",
    "                        em7,\n",
    "                        ja7,\n",
    "                        effect\n",
    "                        )\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "varrelatedis_subs = {}\n",
    "json_open = open('varrelatedis_mitochondria.json', 'r')\n",
    "varscore_mit = json.load(json_open)\n",
    "varrelatedis_subs[\"Mitochondrion\"] = varscore_mit\n",
    "\n",
    "json_open = open('varrelatedis_membrane.json', 'r')\n",
    "varscore_mem = json.load(json_open)\n",
    "varrelatedis_subs[\"Membrane\"] = varscore_mem\n",
    "\n",
    "json_open = open('varrelatedis_nucleus.json', 'r')\n",
    "varscore_nuc = json.load(json_open)\n",
    "varrelatedis_subs[\"Nucleus\"] = varscore_nuc\n",
    "\n",
    "json_open = open('varrelatedis_cytoplasm.json', 'r')\n",
    "varscore_cyt = json.load(json_open)\n",
    "varrelatedis_subs[\"Cytoplasm\"] = varscore_cyt\n",
    "\n",
    "json_open = open('varrelatedis_other.json', 'r')\n",
    "varscore_other = json.load(json_open)\n",
    "varrelatedis_subs[\"Other\"] = varscore_other\n",
    "\n",
    "# JSON形式でファイルに出力する\n",
    "with open('varrelatedis_subcellular.json', 'w') as f:\n",
    "    json.dump(varrelatedis_subs, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiTkIZdoJxZ7"
   },
   "source": [
    "# SUBCELLULAR LOCATION 読んだり、それ使ったりする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9sN9zS59elA"
   },
   "source": [
    "* ACがKey、SUBCELLULAR LOCATIONがValueになるディクショナリを作るコード\n",
    "    * 局在先は2つ以上あることがあるので、keyは文字列、valueはリストにする\n",
    "    * リストの中身に局在先が入ってる\n",
    "* 最終的に作成したディクショナリをJSON形式でファイルに出力する\n",
    "    * ここでは「ac2subcellularlocations.json」というファイルができます。\n",
    "    * acをsubcellular locationに変換するよっていう意味で to と 2 をかけていて、よく使う表現です。\n",
    "\n",
    "* コピペして試すときにはファイル読み込み、JSON書き出しのパスを変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iI5Q7sTC7Wz"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Uniprotのファイルを読み込み\n",
    "data = open(\"/content/drive/MyDrive/geneAnalysis/uniprot_sprot_human.dat\")\n",
    "\n",
    "# 正規表現のパターン定義\n",
    "pattern = r'SUBCELLULAR LOCATION:\\s([\\w\\s\\.]+)[\\{\\,\\.]*'\n",
    "repatter = re.compile(pattern)\n",
    "\n",
    "proteins = defaultdict(list)\n",
    "locations = []\n",
    "acs = []\n",
    "\n",
    "for line in data:\n",
    "    if line.startswith(\"AC\"):\n",
    "        info = line.rstrip().split()\n",
    "\n",
    "        # ACが複数あるときに対応するためリストに入れる\n",
    "        for a in info[1:]:\n",
    "            acs.append(a.replace(\";\",\"\"))            \n",
    "\n",
    "    elif line.startswith(\"CC   -!- SUBCELLULAR LOCATION:\"):\n",
    "        # 正規表現でマッチするところを探す\n",
    "        loc = repatter.search(line)\n",
    "\n",
    "        # locが空っぽじゃなければ＝正規表現でマッチしてたら\n",
    "        if loc is not None:\n",
    "\n",
    "            # ピリオド区切りでいくつか書いてある場合に対応\n",
    "            locs = loc.group(1).rstrip().split(\". \")\n",
    "\n",
    "            # リストに入れる（SUBCELLULAR行が複数ある場合にも対応）\n",
    "            for l in locs:\n",
    "                locations.append(l)\n",
    "\n",
    "    elif line.startswith(\"//\"):\n",
    "        # 複数ACがある場合に対応\n",
    "        for ac in acs:\n",
    "            # 局在先が複数ある場合に対応するためにディクショナリのValueはリストにする\n",
    "            for location in locations:\n",
    "                if location is not None:\n",
    "                    proteins[ac].append(location)\n",
    "\n",
    "        # 以下のリストはappendして使っているので\n",
    "        # エントリの最後でクリアして上げないと、前のエントリの情報と混ざってしまうのでクリア\n",
    "        acs = []\n",
    "        locations = []\n",
    "\n",
    "# JSON形式でファイルに出力する\n",
    "with open('/content/drive/MyDrive/geneAnalysis/ac2subcellularlocations.json', 'w') as f:\n",
    "    json.dump(proteins, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izvH4Z1TqIRG"
   },
   "source": [
    "GOを取得してACと一緒にJSONにするコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEKa6wxMqDV3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Uniprotのファイルを読み込み\n",
    "data = open(\"/content/drive/MyDrive/geneAnalysis/uniprot_sprot_human.dat\")\n",
    "\n",
    "# 正規表現のパターン定義\n",
    "pattern = r'DR   GO; GO:\\d+; ([CFP]):([\\w\\,\\s\\-]+);'\n",
    "repatter = re.compile(pattern)\n",
    "\n",
    "proteins = {}\n",
    "gos = {}\n",
    "for c in [\"F\",\"C\",\"P\"]:\n",
    "    gos[c] = []\n",
    "acs = []\n",
    "seq = \"\"\n",
    "\n",
    "for line in data:\n",
    "    if line.startswith(\"AC\"):\n",
    "        info = line.rstrip().split()\n",
    "\n",
    "        # ACが複数あるときに対応するためリストに入れる\n",
    "        for a in info[1:]:\n",
    "            acs.append(a.replace(\";\",\"\"))            \n",
    "\n",
    "    elif line.startswith(\"DR   GO; GO:\"):\n",
    "        # 正規表現でマッチするところを探す\n",
    "        result = repatter.search(line)\n",
    "\n",
    "        # locが空っぽじゃなければ＝正規表現でマッチしてたら\n",
    "        if result is not None:\n",
    "\n",
    "            # ピリオド区切りでいくつか書いてある場合に対応\n",
    "            goclass = result.group(1)\n",
    "            goterm = result.group(2)\n",
    "\n",
    "            # リストに入れる（GOが複数あるため）\n",
    "            gos[goclass].append(goterm)\n",
    "    elif line.startswith(\"//\"):\n",
    "        seq = \"\".join(seq.split())\n",
    "        # 複数ACがある場合に対応\n",
    "        for ac in acs:\n",
    "            if ac not in proteins.keys():\n",
    "                proteins[ac] = gos\n",
    "\n",
    "        # 以下のリスト、文字列はappendまたは文字列を継ぎ足してして使っているので\n",
    "        # エントリの最後でクリアして上げないと、前のエントリの情報と混ざってしまうのでクリア\n",
    "        gos = {}\n",
    "        for c in [\"F\",\"C\",\"P\"]:\n",
    "            gos[c] = []\n",
    "        acs = []\n",
    "\n",
    "# JSON形式でファイルに出力する\n",
    "with open('/content/drive/MyDrive/geneAnalysis/ac2go.json', 'w') as f:\n",
    "    json.dump(proteins, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTnBjDxf95lj"
   },
   "source": [
    "* 上で作ったACと局在先をまとめたJSONを読み込んで使うコード\n",
    "* 最終的には局在によって変異と疾患の関係が異なっているのか調べている\n",
    "    * ヒートマップの作成（割合、実際の数）\n",
    "    * 100％疾患と関連する変異の洗い出しとそれを持っているタンパク質の抽出\n",
    "    * 80％以上疾患と関連し、疾患になるというエントリが10以上ある変異の洗い出しとタンパク質の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjE1GabdZTLQ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# jsonファイルの読み込み\n",
    "json_open = open('/content/drive/MyDrive/geneAnalysis/ac2subcellularlocations.json', 'r')\n",
    "ac2subcellularlocations = json.load(json_open)\n",
    "json_open = open('/content/drive/MyDrive/geneAnalysis/ac2go.json', 'r')\n",
    "ac2go = json.load(json_open)\n",
    "\n",
    "# 変異と疾患のデータ（humsavar.txt）の読み込み\n",
    "data = open(\"/content/drive/MyDrive/ProteinAnalysis/humsavar_noheader.txt\")\n",
    "\n",
    "disease = defaultdict(int)\n",
    "polymorphism = defaultdict(int)\n",
    "\n",
    "mitochondrion = defaultdict(int)\n",
    "mtDNAcount = defaultdict(int)\n",
    "nucleus = defaultdict(int)\n",
    "cytoplasm = defaultdict(int)\n",
    "membrane = defaultdict(int)\n",
    "\n",
    "aa = ['Ile', 'Val', 'Leu', 'Phe', 'Cys', 'Met', 'Ala', 'Gly', 'Thr', 'Ser', 'Trp', 'Tyr', 'Pro', 'His', 'Glu', 'Gln', 'Asp', 'Asn', 'Lys', 'Arg']\n",
    "\n",
    "# 100%以上疾患と関連する変異のリスト\n",
    "# mit_alldisvar = [\n",
    "#     'IlePhe', 'IleSer', 'IleAsn', 'IleArg', 'ValAsp', 'LeuGly', 'LeuTrp', 'LeuHis',\n",
    "#     'LeuGln', 'PheIle', 'CysPhe', 'CysTyr', 'MetArg', 'AlaGlu','GlyCys', 'GlyTrp',\n",
    "#     'ThrPro', 'SerTyr', 'TrpLeu', 'TrpGly', 'TrpSer', 'TyrAsn', 'ProGln', 'HisLeu',\n",
    "#     'HisAsn', 'GlnGlu', 'AspAla', 'ArgMet', 'ArgThr'\n",
    "#     ]\n",
    "# nuc_alldisvar = ['MetAsn', 'AlaCys', 'TrpLeu', 'AspPhe', 'AspGln']\n",
    "# cyt_alldisvar = ['ValGln', 'CysVal', 'AlaLeu', 'SerHis', 'HisAla', 'GlnGly', 'AsnVal', 'ArgAsp']\n",
    "# mem_alldisvar = ['PheGly', 'AlaIle', 'AlaPhe', 'AlaCys', 'AlaTyr', 'AlaLys', 'GlyLys', 'ThrHis', 'TrpPhe', 'TrpLys', 'HisThr', 'AspCys']\n",
    "# \n",
    "# mitalldiscount = defaultdict(int)\n",
    "# nucalldiscount = defaultdict(int)\n",
    "# cytalldiscount = defaultdict(int)\n",
    "# memalldiscount = defaultdict(int)\n",
    "\n",
    "# 80%以上疾患と関連する変異のリスト、ただし疾患になるデータ数が10以上\n",
    "mit_eightyvar = ['GlyGlu', 'GlyAsp', 'GlyArg', 'TyrCys', 'ProArg', 'ArgPro']\n",
    "nuc_eightyvar = []\n",
    "cyt_eightyvar = ['ValAsp', 'LeuArg', 'PheVal', 'CysPhe', 'TyrAsp']\n",
    "mem_eightyvar = ['IleSer', 'IleArg', 'ValAsp', 'CysPhe', 'CysTyr', 'CysArg', 'SerTrp', 'TrpSer']\n",
    "\n",
    "mtDNA = [\"P03886\",\"P03891\",\"P03897\",\"P03901\",\"P03915\",\"P03923\",\"P00156\",\"P00395\",\"P00403\",\"P00414\",\"P00846\",\"P03928\",\"P03905\"]\n",
    "\n",
    "miteightydiscount = defaultdict(int)\n",
    "nuceightydiscount = defaultdict(int)\n",
    "cyteightydiscount = defaultdict(int)\n",
    "memeightydiscount = defaultdict(int)\n",
    "\n",
    "omimcount = defaultdict(int)\n",
    "varlist = defaultdict(list)\n",
    "antivarlist = defaultdict(list)\n",
    "\n",
    "for line in data:\n",
    "    entries = line.rstrip().split()\n",
    "    geneid, ac, varid, varpattern, effect, rsid = entries[:6]\n",
    "\n",
    "    before = varpattern[2:5]\n",
    "    after = varpattern[-3:]\n",
    "    omim = \",\".join(entries[6:])\n",
    "\n",
    "    # mtDNA にコードされてるエントリだけ出力\n",
    "    # if effect == \"Disease\"  and ac in mtDNA:\n",
    "    #     print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(geneid,ac,before+after,effect,omim))\n",
    "    #     mtDNAcount[effect] += 1\n",
    "\n",
    "    # 変異と疾患のカウント(局在関係なく数える用)\n",
    "    # if effect == \"Disease\":\n",
    "    #     disease[before+after] += 1\n",
    "    # elif effect == \"Polymorphism\":\n",
    "    #     polymorphism[before+after] += 1\n",
    "\n",
    "    if ac in ac2subcellularlocations.keys():\n",
    "        locations_string = \"\".join(ac2subcellularlocations[ac])\n",
    "        if \"Mitochondrion\" in locations_string:\n",
    "            # 局在するタンパク質と疾患との関連性のカウント\n",
    "            mitochondrion[effect] += 1\n",
    "            if ac in mtDNA:\n",
    "                mtDNAcount[effect] += 1\n",
    "                # 変異と疾患のカウント\n",
    "                # if effect == \"Disease\":\n",
    "                #     disease[before+after] += 1\n",
    "                # elif effect == \"Polymorphism\":\n",
    "                #     polymorphism[before+after] += 1\n",
    "\n",
    "            # 疾患関連だったときの疾患名調査\n",
    "            # if effect == \"Disease\" and ac in mtDNA:\n",
    "            #     omimcount[omim] += 1\n",
    "\n",
    "            # 変異と疾患のカウント\n",
    "            # if effect == \"Disease\":\n",
    "            #     disease[before+after] += 1\n",
    "            # elif effect == \"Polymorphism\":\n",
    "            #     polymorphism[before+after] += 1\n",
    "\n",
    "            # 100％疾患と関連する変異を持つタンパク質を抽出\n",
    "            # if before+after in mit_alldisvar:\n",
    "            #     mitalldiscount[ac] += 1\n",
    "\n",
    "            # 80％疾患と関連する変異を持つタンパク質を抽出\n",
    "            # if before+after in mit_eightyvar:\n",
    "            #     miteightydiscount[ac] += 1\n",
    "            #     varlist[ac].append(varpattern+\"/\"+effect+\"/\"+omim)\n",
    "            # else:\n",
    "            #     antivarlist[ac].append(\"-\"+varpattern+\"/\"+effect+\"/\"+omim)\n",
    "\n",
    "        elif \"Nucleus\" in locations_string:\n",
    "            # 局在するタンパク質と疾患との関連性のカウント\n",
    "            nucleus[effect] += 1\n",
    "            \n",
    "            # 疾患関連だったときの疾患名調査\n",
    "            # if effect == \"Disease\":\n",
    "            #     omimcount[omim] += 1\n",
    "\n",
    "            # 変異と疾患のカウント\n",
    "            # if effect == \"Disease\":\n",
    "            #     disease[before+after] += 1\n",
    "            # elif effect == \"Polymorphism\":\n",
    "            #     polymorphism[before+after] += 1\n",
    "\n",
    "            # 100％疾患と関連する変異を持つタンパク質を抽出\n",
    "            # if before+after in nuc_alldisvar:\n",
    "            #     nucalldiscount[ac] += 1\n",
    "\n",
    "            # 80％疾患と関連する変異を持つタンパク質を抽出\n",
    "            # if before+after in nuc_eightyvar:\n",
    "            #     nuceightydiscount[ac] += 1\n",
    "\n",
    "        elif \"Cytoplasm\" in locations_string:\n",
    "            # 局在するタンパク質と疾患との関連性のカウント\n",
    "            cytoplasm[effect] += 1\n",
    "\n",
    "            # 変異と疾患のカウント\n",
    "            # if effect == \"Disease\":\n",
    "            #     disease[before+after] += 1\n",
    "            # elif effect == \"Polymorphism\":\n",
    "            #     polymorphism[before+after] += 1\n",
    "\n",
    "            # 100％疾患と関連する変異を持つタンパク質を抽出\n",
    "            # if before+after in cyt_alldisvar:\n",
    "            #     cytalldiscount[ac] += 1\n",
    "\n",
    "            # 80％疾患と関連する変異を持つタンパク質を抽出\n",
    "            # if before+after in cyt_eightyvar:\n",
    "            #     cyteightydiscount[ac] += 1\n",
    "\n",
    "        elif \"embrane\" in locations_string:\n",
    "            # 局在するタンパク質と疾患との関連性のカウント\n",
    "            membrane[effect] += 1\n",
    "\n",
    "            # 変異と疾患のカウント\n",
    "            # if effect == \"Disease\":\n",
    "            #     disease[before+after] += 1\n",
    "            # elif effect == \"Polymorphism\":\n",
    "            #     polymorphism[before+after] += 1\n",
    "\n",
    "            # 100％疾患と関連する変異を持つタンパク質を抽出\n",
    "            # if before+after in mem_alldisvar:\n",
    "            #     memalldiscount[ac] += 1\n",
    "\n",
    "            # 80％疾患と関連する変異を持つタンパク質を抽出\n",
    "            # if before+after in mem_eightyvar:\n",
    "            #     memeightydiscount[ac] += 1\n",
    "        else:\n",
    "            # 変異と疾患のカウント\n",
    "            if effect == \"Disease\":\n",
    "                disease[before+after] += 1\n",
    "            elif effect == \"Polymorphism\":\n",
    "                polymorphism[before+after] += 1\n",
    "    else:\n",
    "        # 変異と疾患のカウント\n",
    "        if effect == \"Disease\":\n",
    "            disease[before+after] += 1\n",
    "        elif effect == \"Polymorphism\":\n",
    "            polymorphism[before+after] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 出力パート\n",
    "\n",
    "# 拾ってきた ac について出力\n",
    "# for ac,n in sorted(miteightydiscount.items(),key=lambda x:x[1],reverse=True):\n",
    "#     print(\"{}\\t{}\".format(ac,n))\n",
    "#     for v in varlist[ac]:\n",
    "#         print(v)\n",
    "#     for v in antivarlist[ac]:\n",
    "#         print(v)\n",
    "#     for p in [\"F\",\"C\",\"P\"]:\n",
    "#         for f in ac2go[ac][p]:\n",
    "#             print(\"{}: {}\".format(p,f))\n",
    "#     print()\n",
    "\n",
    "\n",
    "# 疾患名カウントの結果出力\n",
    "# 数が多い方から順に出力\n",
    "# for k,v in sorted(omimcount.items(),key=lambda x:x[1], reverse=True):\n",
    "#     print(\"{}\\t{}\".format(k,v))\n",
    "#     if v < 10:\n",
    "#         break\n",
    "\n",
    "# 下で作った80％疾患と関連する変異のリストから\n",
    "# その変異をもつタンパク質と持っている変異の数を出力\n",
    "# print(\"Mitochondrion\")\n",
    "# for k,v in miteightydiscount.items():\n",
    "#     if v > 4:\n",
    "#         print(\"{}\\t{}\".format(k,v))\n",
    "# print()\n",
    "# print(\"Nucleus\")\n",
    "# for k,v in nuceightydiscount.items():\n",
    "#     if v > 4:\n",
    "#         print(\"{}\\t{}\".format(k,v))\n",
    "# print()\n",
    "# print(\"Cytoplasm\")\n",
    "# for k,v in cyteightydiscount.items():\n",
    "#     if v > 4:\n",
    "#         print(\"{}\\t{}\".format(k,v))\n",
    "# print()\n",
    "# print(\"Membrane\")\n",
    "# for k,v in memeightydiscount.items():\n",
    "#     if v > 4:\n",
    "#         print(\"{}\\t{}\".format(k,v))\n",
    "\n",
    "# 80％疾患と関連する変異のカウント\n",
    "# 局在先ごとにリストにして上に。\n",
    "# eightydiseasevar = []\n",
    "# for b in aa:\n",
    "#     for a in aa:\n",
    "#         var = b + a\n",
    "#         d = 0 if var not in disease else disease[var]\n",
    "#         p = 0 if var not in polymorphism else polymorphism[var]\n",
    "#         if d + p != 0 and d / (d + p) >= 0.8 and d > 10:\n",
    "#             eightydiseasevar.append(var)\n",
    "#             print(\"{}\\t{}\\t{}\\t{}\".format(var,d/(d+p),d,p))\n",
    "# print(eightydiseasevar)\n",
    "\n",
    "\n",
    "# 下で作った100％疾患と関連する変異のリストから\n",
    "# その変異をもつタンパク質と持っている変異の数を出力\n",
    "# print(\"Mitochondrion\")\n",
    "# for k,v in mitalldiscount.items():\n",
    "#     print(\"{}\\t{}\".format(k,v))\n",
    "# print()\n",
    "# print(\"Nucleus\")\n",
    "# for k,v in nucalldiscount.items():\n",
    "#     print(\"{}\\t{}\".format(k,v))\n",
    "# print()\n",
    "# print(\"Cytoplasm\")\n",
    "# for k,v in cytalldiscount.items():\n",
    "#     print(\"{}\\t{}\".format(k,v))\n",
    "# print()\n",
    "# print(\"Membrane\")\n",
    "# for k,v in memalldiscount.items():\n",
    "#     print(\"{}\\t{}\".format(k,v))\n",
    "\n",
    "# 100％疾患と関連する変異のカウント\n",
    "# 局在先ごとにリストにして上に。\n",
    "# alldiseasevar = []\n",
    "# for b in aa:\n",
    "#     for a in aa:\n",
    "#         var = b + a\n",
    "#         d = 0 if var not in disease else disease[var]\n",
    "#         p = 0 if var not in polymorphism else polymorphism[var]\n",
    "#         if d + p != 0 and d / (d + p) == 1 and d > 0:\n",
    "#             alldiseasevar.append(var)\n",
    "#             # print(\"{}\\t{}\\t{}\\t{}\".format(var,d/(d+p),d,p))\n",
    "# print(alldiseasevar)\n",
    "\n",
    "\n",
    "# ヒートマップ用の割合を出力\n",
    "# 局在位置ごとに見るときには上のif文で欲しい局在のところだけでカウントする\n",
    "# print(\"\\t\".join(aa))\n",
    "# for b in aa:\n",
    "#     print(\"{}\\t\".format(b),end=\"\")\n",
    "#     for a in aa:\n",
    "#         var = b + a\n",
    "#         d = 0 if var not in disease else disease[var]\n",
    "#         p = 0 if var not in polymorphism else polymorphism[var]\n",
    "\n",
    "#         if d + p != 0:\n",
    "#             print(\"{}\\t\".format(d / (d + p)),end=\"\")\n",
    "#         else:\n",
    "#             print(\"-\\t\",end=\"\")\n",
    "#     print()\n",
    "# print()\n",
    "\n",
    "# ヒートマップをJSONにする\n",
    "heatmap = defaultdict(dict)\n",
    "for b in aa:\n",
    "    for a in aa:\n",
    "        var = b + a\n",
    "        d = 0 if var not in disease else disease[var]\n",
    "        p = 0 if var not in polymorphism else polymorphism[var]\n",
    "\n",
    "        if d + p != 0:\n",
    "            heatmap[b][a] = d / (d + p)\n",
    "        else:\n",
    "            heatmap[b][a] = -1\n",
    "# JSON形式でファイルに出力する\n",
    "with open('/content/drive/MyDrive/geneAnalysis/varrelatedis_other.json', 'w') as f:\n",
    "    json.dump(heatmap, f, indent=4)\n",
    "\n",
    "# print(\"\\t\".join(aa))\n",
    "# for b in aa:\n",
    "#     print(\"{}\\t\".format(b),end=\"\")\n",
    "#     for a in aa:\n",
    "#         var = b + a\n",
    "#         d = 0 if var not in disease else disease[var]\n",
    "#         p = 0 if var not in polymorphism else polymorphism[var]\n",
    "\n",
    "#         if d + p != 0:\n",
    "#             print(\"{}\\t\".format(d),end=\"\")\n",
    "#         else:\n",
    "#             print(\"-\\t\",end=\"\")\n",
    "#     print()\n",
    "# print()\n",
    "\n",
    "# print(\"\\t\".join(aa))\n",
    "# for b in aa:\n",
    "#     print(\"{}\\t\".format(b),end=\"\")\n",
    "#     for a in aa:\n",
    "#         var = b + a\n",
    "#         d = 0 if var not in disease else disease[var]\n",
    "#         p = 0 if var not in polymorphism else polymorphism[var]\n",
    "\n",
    "#         if d + p != 0:\n",
    "#             print(\"{}\\t\".format(p),end=\"\")\n",
    "#         else:\n",
    "#             print(\"-\\t\",end=\"\")\n",
    "#     print()\n",
    "\n",
    "\n",
    "# 局在位置のカウントを出力\n",
    "# print(mitochondrion)\n",
    "# print(nucleus)\n",
    "# print(cytoplasm)\n",
    "# print(membrane)\n",
    "# print(mtDNAcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# jsonファイルの読み込み\n",
    "json_open = open('ac2subcellularlocations_sorted3.json', 'r')\n",
    "ac2subcellularlocations = json.load(json_open)\n",
    "\n",
    "# 変異と疾患のデータ（humsavar.txt）の読み込み\n",
    "data = open(\"humsavar_noheader.txt\")\n",
    "subcel = [\"Mitochondrion\",\"Nucleus\",\"Cytoplasm\",\"membrane\",\"Secreted\",\"ER-golgi\",\"others\",]\n",
    "\n",
    "disease = {}\n",
    "polymorphism = {}\n",
    "for s in subcel:\n",
    "    disease[s] = defaultdict(int)\n",
    "    polymorphism[s] = defaultdict(int)\n",
    "\n",
    "aa = ['Ile', 'Val', 'Leu', 'Phe', 'Cys', 'Met', 'Ala', 'Gly', 'Thr', 'Ser', 'Trp', 'Tyr', 'Pro', 'His', 'Glu', 'Gln', 'Asp', 'Asn', 'Lys', 'Arg']\n",
    "\n",
    "for line in data:\n",
    "    entries = line.rstrip().split()\n",
    "    geneid, ac, varid, varpattern, effect, rsid = entries[:6]\n",
    "\n",
    "    before = varpattern[2:5]\n",
    "    after = varpattern[-3:]\n",
    "    omim = \",\".join(entries[6:])\n",
    "\n",
    "    if ac in ac2subcellularlocations.keys():\n",
    "        for compartment in ac2subcellularlocations[ac]:\n",
    "            if compartment not in subcel:\n",
    "                continue\n",
    "\n",
    "            # 変異と疾患のカウント\n",
    "            if effect == \"Disease\":\n",
    "                disease[compartment][before+after] += 1\n",
    "            elif effect == \"Polymorphism\":\n",
    "                polymorphism[compartment][before+after] += 1\n",
    "            \n",
    "## 出力パート\n",
    "# ヒートマップ用の割合を出力\n",
    "# 局在位置ごとに見るときには上のif文で欲しい局在のところだけでカウントする\n",
    "# for s in subcel:\n",
    "#     print(\"{}\\t{}\".format(s,\"\\t\".join(aa)))\n",
    "#     for b in aa:\n",
    "#         print(\"{}\\t\".format(b),end=\"\")\n",
    "#         for a in aa:\n",
    "#             var = b + a\n",
    "#             d = 0 if var not in disease[s] else disease[s][var]\n",
    "#             p = 0 if var not in polymorphism[s] else polymorphism[s][var]\n",
    "\n",
    "#             if d + p != 0:\n",
    "#                 print(\"{}\\t\".format(d / (d + p)),end=\"\")\n",
    "#             else:\n",
    "#                 print(\"-\\t\",end=\"\")\n",
    "#         print()\n",
    "#     print()\n",
    "\n",
    "# ヒートマップをJSONにする\n",
    "heatmap = {}\n",
    "for s in subcel:\n",
    "    heatmap[s] = defaultdict(dict)\n",
    "for s in subcel:\n",
    "    for b in aa:\n",
    "        for a in aa:\n",
    "            var = b + a\n",
    "            d = 0 if var not in disease[s] else disease[s][var]\n",
    "            p = 0 if var not in polymorphism[s] else polymorphism[s][var]\n",
    "\n",
    "            if d + p != 0:\n",
    "                heatmap[s][b][a] = d / (d + p)\n",
    "            else:\n",
    "                heatmap[s][b][a] = -1\n",
    "# JSON形式でファイルに出力する\n",
    "with open('pd_subcellular.json', 'w') as f:\n",
    "    json.dump(heatmap, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-MSSDldAjxz"
   },
   "source": [
    "# JSON作ったり、それ使ったりする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQhb23rL2vmS"
   },
   "source": [
    "- ACとアミノ酸配列のJSONを作成するコード\n",
    "    - アミノ酸配列は1文字表記で記述される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZmpAasC2VMD"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Uniprotのファイルを読み込み\n",
    "data = open(\"/content/drive/MyDrive/geneAnalysis/uniprot_sprot_human.dat\")\n",
    "\n",
    "proteins = {}\n",
    "seq = \"\"\n",
    "\n",
    "for line in data:\n",
    "    if line.startswith(\"AC\"):\n",
    "        info = line.rstrip().split()\n",
    "\n",
    "        # ACが複数あるときに対応するためリストに入れる\n",
    "        for a in info[1:]:\n",
    "            acs.append(a.replace(\";\",\"\"))            \n",
    "\n",
    "    elif line.startswith(\"  \"):\n",
    "        # 配列がファイル内で複数行にまたがるので、つなぎ合わせる\n",
    "        seq += line.rstrip()\n",
    "    elif line.startswith(\"//\"):\n",
    "        # 繋いだ配列文字列から空白を削除\n",
    "        # 空白でsplitしてjoinしてる\n",
    "        seq = \"\".join(seq.split())\n",
    "        \n",
    "        # 複数ACがある場合に対応\n",
    "        for ac in acs:\n",
    "            if ac not in proteins.keys():\n",
    "                proteins[ac] = seq\n",
    "\n",
    "        # 以下のリスト、文字列はappendまたは文字列を継ぎ足してして使っているので\n",
    "        # エントリの最後でクリアして上げないと、前のエントリの情報と混ざってしまうのでクリア\n",
    "        acs = []\n",
    "        seq = \"\"\n",
    "\n",
    "# JSON形式でファイルに出力する\n",
    "with open('/content/drive/MyDrive/geneAnalysis/ac2seq.json', 'w') as f:\n",
    "    json.dump(proteins, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACとPDBをつなぐJSONをつくるコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZmpAasC2VMD"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "# Uniprotのファイルを読み込み\n",
    "data = open(\"uniprot_sprot_human.dat\")\n",
    "\n",
    "# 正規表現のパターン定義\n",
    "pattern = r'DR\\s+PDB;\\s+([0-9A-Z]+);\\s+[\\w\\-]+;\\s[0-9\\.\\s\\-A]+;\\s+([A-Za-z0-9\\/]+)=([0-9\\-]+)'\n",
    "# DR   PDB; 2BQ0; X-ray; 2.50 A; A/B=2-239.\n",
    "# DR   PDB; 2JTG; NMR; -; A=1-81.\n",
    "repatter = re.compile(pattern)\n",
    "\n",
    "proteins = {}\n",
    "acs = []\n",
    "pdb_chain = []\n",
    "\n",
    "for line in data:\n",
    "    if line.startswith(\"AC\"):\n",
    "        info = line.rstrip().split()\n",
    "\n",
    "        # ACが複数あるときに対応するためリストに入れる\n",
    "        for a in info[1:]:\n",
    "            acs.append(a.replace(\";\",\"\"))            \n",
    "\n",
    "    elif line.startswith(\"DR   PDB;\"):\n",
    "        # 正規表現でマッチするところを探す\n",
    "        result = repatter.search(line)\n",
    "        \n",
    "        # locが空っぽじゃなければ＝正規表現でマッチしてたら\n",
    "        if result is not None:\n",
    "\n",
    "            # ピリオド区切りでいくつか書いてある場合に対応\n",
    "            pdbcode = result.group(1)\n",
    "            chain = result.group(2)\n",
    "            structrange = result.group(3)\n",
    "\n",
    "            for c in chain.split(\"/\"):\n",
    "                pdb_chain.append({\"PDB\":pdbcode.lower()+c,\"range\":structrange}) \n",
    "    elif line.startswith(\"//\"):\n",
    "        if len(pdb_chain) != 0:\n",
    "        # 複数ACがある場合に対応\n",
    "            for ac in acs:\n",
    "                if ac not in proteins.keys():\n",
    "                    proteins[ac] = pdb_chain\n",
    "\n",
    "        # 以下のリスト、文字列はappendまたは文字列を継ぎ足してして使っているので\n",
    "        # エントリの最後でクリアして上げないと、前のエントリの情報と混ざってしまうのでクリア\n",
    "        acs = []\n",
    "        pdb_chain = []\n",
    "\n",
    "# JSON形式でファイルに出力する\n",
    "with open('ac2pdb.json', 'w') as f:\n",
    "    json.dump(proteins, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ACと細胞内局在、ecodを元にした構造情報をまとめてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# jsonファイルの読み込み\n",
    "json_open = open('ac2pdb.json', 'r')\n",
    "ac2pdb = json.load(json_open)\n",
    "json_open = open('ac2subcellularlocations.json', 'r')\n",
    "ac2sub = json.load(json_open)\n",
    "json_open = open('ecod.json', 'r')\n",
    "ecod = json.load(json_open)\n",
    "\n",
    "arch_dis = defaultdict(int) \n",
    "x_dis = defaultdict(int)\n",
    "t_dis = defaultdict(int)\n",
    "arch_pol = defaultdict(int)\n",
    "x_pol = defaultdict(int)\n",
    "t_pol = defaultdict(int)\n",
    "dis = set()\n",
    "pol = set()\n",
    "dis_ecod = set()\n",
    "pol_ecod = set()\n",
    "\n",
    "\n",
    "flag = False\n",
    "for line in open(\"humsavar_noheader.txt\"):\n",
    "    entries = line.rstrip().split()\n",
    "    geneid, ac, varid, varpattern, effect, rsid = entries[:6]\n",
    "\n",
    "    if ac not in ac2sub.keys() or effect == \"Unclassified\": continue\n",
    "    if effect == \"Disease\":\n",
    "        dis.add(ac)\n",
    "    else:\n",
    "        pol.add(ac)\n",
    "\n",
    "    for sub in ac2sub[ac]:\n",
    "        if \"ucleus\" in sub:\n",
    "            flag = True\n",
    "            break\n",
    "\n",
    "    if not flag or ac not in ac2pdb: continue\n",
    "\n",
    "    for pdb in ac2pdb[ac]:\n",
    "        if pdb[\"PDB\"] in ecod.keys():\n",
    "            if effect == \"Disease\":\n",
    "                dis_ecod.add(ac)\n",
    "                arch_dis[ecod[pdb[\"PDB\"]][0][\"arch_name\"]] += 1\n",
    "                x_dis[ecod[pdb[\"PDB\"]][0][\"x_name\"]] += 1\n",
    "                t_dis[ecod[pdb[\"PDB\"]][0][\"t_name\"]] += 1\n",
    "            elif effect == \"Polymorphism\":\n",
    "                pol_ecod.add(ac)\n",
    "                arch_pol[ecod[pdb[\"PDB\"]][0][\"arch_name\"]] += 1\n",
    "                x_pol[ecod[pdb[\"PDB\"]][0][\"x_name\"]] += 1\n",
    "                t_pol[ecod[pdb[\"PDB\"]][0][\"t_name\"]] += 1\n",
    "            break\n",
    "    flag = False            \n",
    "\n",
    "for k,v in sorted(arch_dis.items(),key=lambda x:x[1],reverse=True):\n",
    "    print(\"{}\\t{}\\t{}\".format(k,v,arch_pol[k]))\n",
    " \n",
    "print(\"{}\\t{}\".format(len(dis),len(pol)))\n",
    "print(\"{}\\t{}\".format(len(dis_ecod),len(pol_ecod)))\n",
    "for ac in dis_ecod:\n",
    "    print(\"{}\\t{}\".format(ac,ecod[ac2pdb[ac][0][\"PDB\"]][0][\"arch_name\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cXAXCNO_39l"
   },
   "source": [
    "- ACから配列を呼び出すJSON、ac2seq.jsonを使って配列の長さを導くコード\n",
    "    - 文字列の長さを計算する関数 len()をつかうだけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDVBp1Ie_U1e",
    "outputId": "eb3f4162-324a-4d35-b310-7a5fb7ac226d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# jsonファイルの読み込み\n",
    "json_open = open('/content/drive/MyDrive/geneAnalysis/ac3seq.json', 'r')\n",
    "ac2seq = json.load(json_open)\n",
    "\n",
    "proteins = [\"P03886\",\"P03891\",\"P03897\"]\n",
    "for p in proteins:\n",
    "    print(\"{}\\t{}\".format(p,len(ac2seq[p])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq6bBQ7FVmcG"
   },
   "source": [
    "pymolでまとめて選択するコマンド作るためのコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1mJQTiD_1Rh",
    "outputId": "b827044b-4a49-4b64-f452-098dc7827cba"
   },
   "outputs": [],
   "source": [
    "# 変異と疾患のデータ（humsavar.txt）の読み込み\n",
    "data = open(\"/content/drive/MyDrive/ProteinAnalysis/humsavar_noheader.txt\")\n",
    "\n",
    "# コマンド作るタンパク質のAC\n",
    "target = \"P31327\"\n",
    "vareffect = \"Disease\"\n",
    "#vareffect = \"Polymorphism\"\n",
    "\n",
    "residues = []\n",
    "\n",
    "for line in data:\n",
    "    entries = line.rstrip().split()\n",
    "    geneid, ac, varid, varpattern, effect, rsid = entries[:6]\n",
    "\n",
    "    if ac == target and effect == vareffect:\n",
    "        before = varpattern[2:5]\n",
    "        after = varpattern[-3:]\n",
    "        position = int(varpattern[5:-3])\n",
    "        residues.append(position)\n",
    "\n",
    "print(\"select (resi \", end=\"\")\n",
    "for r in residues:\n",
    "    print(\"{},\".format(r),end=\"\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intspan import intspan\n",
    "# 1-105 と 78-153がどれだけ重なっているか考える場合\n",
    "\n",
    "a = set(intspan(\"1-105\")).intersection(set(intspan(\"78-153\")))\n",
    "print(a)\n",
    "print(max(a))\n",
    "print(intspan(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intspan import intspan\n",
    "\n",
    "# predict.txtとdatabase.txtを読み込む\n",
    "predict_regions = ['1-105','200-254']\n",
    "database_regions = ['78-153','234-278']\n",
    "\n",
    "# 予測した領域のリストとデータベースから取り出した領域のリストを比較する\n",
    "correct_predictions = []\n",
    "for predict_region in predict_regions:\n",
    "    predict_set = intspan(predict_region)\n",
    "    for database_region in database_regions:\n",
    "        database_set = intspan(database_region)\n",
    "        overlap = predict_set & database_set\n",
    "        if overlap:\n",
    "            correct_predictions.append(str(overlap))\n",
    "\n",
    "print(f'正確に予測された領域:{correct_predictions}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference\n",
    "# https://www.tije.co/post/seqlogo_from_multiple_sequence_alignment/\n",
    "import sys\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "import subprocess\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from Bio import TogoWS, SeqIO\n",
    "from Bio.Blast import NCBIXML\n",
    "from io import StringIO\n",
    "import json\n",
    "\n",
    "\n",
    "query_ac = \"P04217\"\n",
    "\n",
    "# タンパク質単体のfastaファイル作る\n",
    "child = subprocess.Popen(['blastdbcmd','-db','uniprot_sprot_human.faa','-entry',query_ac],stdin=subprocess.PIPE,stdout=subprocess.PIPE)\n",
    "query_fasta = child.communicate()[0].decode('utf8')\n",
    "print(query_fasta)\n",
    "print()\n",
    "\n",
    "# fastaファイルを使ってblast\n",
    "# 相手は脊椎動物のタンパク質\n",
    "# xmlで出力\n",
    "child = subprocess.Popen(['blastp','-db','uniprot_sprot_mammals_vertebrates.faa','-outfmt','5','-evalue','0.1','-query','-'],stdin=subprocess.PIPE,stdout=subprocess.PIPE)\n",
    "child.stdin.write(query_fasta.encode())\n",
    "blast_xml = child.communicate()[0].decode('utf8')\n",
    "# xmlをread\n",
    "blast_result = NCBIXML.read(StringIO(blast_xml))\n",
    "\n",
    "aln_ac = []\n",
    "# Alignment部分の取得\n",
    "# 相同性検索で引っかかったACを取得（e-value>0.1）\n",
    "# blastdbcmdの引数にするためにカンマ区切りの文字列を作成\n",
    "alignments = blast_result.alignments\n",
    "for alignment in alignments:\n",
    "    aln_ac.append(alignment.accession)\n",
    "aln_ac_string = ','.join(aln_ac)\n",
    "print(aln_ac_string)\n",
    "\n",
    "# blastdbcmdの実行\n",
    "# mafftにかけるためのmultifastaを作る\n",
    "child = subprocess.Popen(['blastdbcmd','-db','uniprot_sprot_mammals_vertebrates.faa','-entry',aln_ac_string],stdin=subprocess.PIPE,stdout=subprocess.PIPE)\n",
    "ortholog_fasta = child.communicate()[0].decode('utf8')\n",
    "# query自身が含まれていないので先頭に追加\n",
    "ortholog_fasta = query_fasta + \"\\n\" + ortholog_fasta\n",
    "print(ortholog_fasta)\n",
    "\n",
    "# mafftの実行\n",
    "child = subprocess.Popen(['mafft','--quiet','--clustalout','-'],stdin=subprocess.PIPE,stdout=subprocess.PIPE)\n",
    "child.stdin.write(ortholog_fasta.encode())\n",
    "child_out = child.communicate()[0].decode('utf8')\n",
    "aln = AlignIO.read(StringIO(child_out),'clustal')\n",
    "print(aln)\n",
    "\n",
    "query = list(SeqIO.parse(StringIO(query_fasta), 'fasta'))\n",
    "query_seq = query[0].seq\n",
    "print(query_seq)\n",
    "\n",
    "\n",
    "# あるタンパク質のある場所におけるアミノ酸の頻度を計算するためのdictionaryを作成\n",
    "# 集めた相同タンパク質で全部一致するとその場所のそのアミノ酸の頻度が1.0になる\n",
    "characters=\"ACDEFGHIKLMNPQRSTVWY\"\n",
    "alnRows = aln.get_alignment_length()\n",
    "compDict = {char:[0]*alnRows for char in characters}\n",
    "alignment_info = []\n",
    "for record in aln:\n",
    "    header = record.id\n",
    "    seq = record.seq\n",
    "    alignment_info.append({'ac':header,'seq':str(seq)})\n",
    "    for i,aa in enumerate(seq):\n",
    "        if aa in characters:\n",
    "            compDict[aa][i] += 1 \n",
    "\n",
    "aln_sitecompDF = pd.DataFrame.from_dict(compDict)\n",
    "aln_sitecompFreq = aln_sitecompDF.div(aln_sitecompDF.sum(axis=1),axis=0)\n",
    "# aln_sitecompFreq.to_csv('out_test3.tsv',sep='\\t', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "query_ac = \"P04217\"\n",
    "query_seq = \"MSMLVVFLLLWGVTWGPVTEAAIFYETQPSLWAESESLLKPLANVTLTCQAHLETPDFQLFKNGVAQEPVHLDSPAIKHQFLLTGDTQGRYRCRSGLSTGWTQLSKLLELTGPKSLPAPWLSMAPVSWITPGLKTTAVCRGVLRGVTFLLRREGDHEFLEVPEAQEDVEATFPVHQPGNYSCSYRTDGEGALSEPSATVTIEELAAPPPPVLMHHGESSQVLHPGNKVTLTCVAPLSGVDFQLRRGEKELLVPRSSTSPDRIFFHLNAVALGDGGHYTCRYRLHDNQNGWSGDSAPVELILSDETLPAPEFSPEPESGRALRLRCLAPLEGARFALVREDRGGRRVHRFQSPAGTEALFELHNISVADSANYSCVYVDLKPPFGGSAPSERLELHVDGPPPRPQLRATWSGAVLAGRDAVLRCEGPIPDVTFELLREGETKAVKTVRTPGAAANLELIFVGPQHAGNYRCRYRSWVPHTFESELSDPVELLVAES\"\n",
    "aln = AlignIO.read(\"mafft_P04217.txt\",'clustal')\n",
    "\n",
    "characters=\"ACDEFGHIKLMNPQRSTVWY-\"\n",
    "#compDict = {char:[0]*len(query_seq) for char in characters}\n",
    "compDict = {}\n",
    "compRatio = {}\n",
    "\n",
    "for i in range(len(query_seq)):\n",
    "    compDict[i] = defaultdict(int)\n",
    "    compRatio[i] = {}\n",
    "\n",
    "alignment_info = {}\n",
    "\n",
    "for record in aln:\n",
    "    header = record.id\n",
    "    seq = record.seq\n",
    "    alignment_info[header] = str(seq)\n",
    "    # for i,aa in enumerate(seq):\n",
    "    #     if aa in characters:\n",
    "    #         compDict[aa][i] += 1\n",
    "\n",
    "query_position = 0\n",
    "for i,aa in enumerate(alignment_info[query_ac]):\n",
    "    if aa == \"-\":\n",
    "        continue\n",
    "    for orth_ac,orth_seq in alignment_info.items():\n",
    "        if orth_seq[i] in characters:\n",
    "            compDict[query_position][orth_seq[i]] += 1\n",
    "    query_position += 1\n",
    "\n",
    "orth_num = len(alignment_info)\n",
    "for i,d in compDict.items():\n",
    "    for aa,num in d.items():\n",
    "        compRatio[i][aa] = round(num/orth_num,5)\n",
    "print(compRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"humsavar_noheader.txt\")\n",
    "\n",
    "acs = set()\n",
    "for line in data:\n",
    "    entry = line.rstrip().split()\n",
    "    geneid, ac, varid, varpattern, effect, rsid = entry[:6]\n",
    "    acs.add(ac)\n",
    "for ac in list(acs):\n",
    "    print(ac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# jsonファイルの読み込み\n",
    "json_open = open('ac2subcellularlocations_sorted3_othersCapital.json', 'r')\n",
    "ac2subcellularlocations = json.load(json_open)\n",
    "\n",
    "# jsonファイルの読み込み\n",
    "json_open = open('ac2seq.json', 'r')\n",
    "ac2seq = json.load(json_open)\n",
    "\n",
    "mtDNA = [\"P03886\",\"P03891\",\"P03897\",\"P03901\",\"P03915\",\"P03923\",\"P00156\",\"P00395\",\"P00403\",\"P00414\",\"P00846\",\"P03928\",\"P03905\"]\n",
    "\n",
    "for ac in mtDNA:\n",
    "    seq = ac2seq[ac]\n",
    "    ave = calcAve(kd,seq)\n",
    "    print(\"mtDNA\\t{}\".format(ave))\n",
    "    \n",
    "for line in open(\"uniprot_sprot_human_ac.dat\"):\n",
    "    ac = line.rstrip()\n",
    "    if ac in ac2subcellularlocations and \"Mitochondrion\" in ac2subcellularlocations[ac]:\n",
    "        if ac in ac2seq:\n",
    "            seq = ac2seq[ac]\n",
    "        ave = calcAve(kd,seq)\n",
    "        print(\"genomeDNA\\t{}\".format(ave))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('/Users/tsuji/Google Drive/マイドライブ/geneAnalysis/databases/AlphaMissense_aa_substitutions.tsv'):\n",
    "    if line.startswith('#') or line.startswith('uniprot'):\n",
    "        continue\n",
    "\n",
    "    initchar = line[0:2]\n",
    "    with open('./AlphaMissense/{}.tsv'.format(initchar), mode='a') as f:\n",
    "        f.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('AlphaMissense/Q9.tsv'):\n",
    "    if line.startswith('#') or line.startswith('uniprot'):\n",
    "        continue\n",
    "\n",
    "    initchar = line[0:3]\n",
    "    with open('./AlphaMissense/{}.tsv'.format(initchar), mode='a') as f:\n",
    "        f.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_open = open('./gene2ac.json', 'r')\n",
    "gene2ac = json.load(json_open)\n",
    "\n",
    "outfile = open('./ToMMo_exon_snv_alphamissense.tsv',mode='w')\n",
    "counter = 0\n",
    "\n",
    "previous = ''\n",
    "for line in open('./ToMMo_exon_snv.tsv'):\n",
    "    if(line.startswith('chrom')):\n",
    "        continue\n",
    "    entry = line.rstrip().split()\n",
    "    gene = entry[4]\n",
    "    nm = entry[5]\n",
    "    var = entry[6]\n",
    "    ac = ''\n",
    "    if gene in gene2ac:\n",
    "        ac = gene2ac[gene]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if ac != previous:\n",
    "        if counter > 0:\n",
    "            data.close()\n",
    "        previous = ac\n",
    "        if ac.startswith('Q8') or ac.startswith('Q9'):\n",
    "            data = open('./AlphaMissense/{}.tsv'.format(ac[0:3]))\n",
    "        else:\n",
    "            data = open('./AlphaMissense/{}.tsv'.format(ac[0:2]))\n",
    "            \n",
    "    for am in data:\n",
    "        amac,amvar,amscore,ameffect = am.split()\n",
    "        if ac == amac and var == amvar:\n",
    "            print('{}\\t{}\\t{}\\t{}'.format(ac,var,amac,amvar))\n",
    "            break\n",
    "            #outfile.write('{}\\t{}\\n'.format(line.rstrip(),amscore))\n",
    "    \n",
    "    counter = +1\n",
    "    if counter%100 == 0:\n",
    "        break\n",
    "\n",
    "outfile.close()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = 'p.His160Arg'\n",
    "var2 = 'p.His16Arg'\n",
    "print(var1[2:5])\n",
    "print(var1[-3:])\n",
    "print(var1[5:-3])\n",
    "\n",
    "print(var2[5:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import defaultdict\n",
    "data = open(\"humsavar_noheader_20240604.txt\")\n",
    "\n",
    "p = {}\n",
    "b = {}\n",
    "\n",
    "for line in data:\n",
    "    ac = line.rstrip().split()[1]\n",
    "    major = line.rstrip().split()[3][2:5]\n",
    "    minor = line.rstrip().split()[3][-3:]\n",
    "    effect = line.rstrip().split()[4]\n",
    "    if effect == 'LP/P':\n",
    "        if major+minor not in p:\n",
    "            p[major+minor] = 0\n",
    "        p[major+minor] += 1\n",
    "    elif effect == 'LB/B':\n",
    "        if major+minor not in b:\n",
    "            b[major+minor] = 0\n",
    "        b[major+minor] += 1\n",
    "\n",
    "aa = ['Ile', 'Val', 'Leu', 'Phe', 'Cys', 'Met', 'Ala', 'Gly', 'Thr', 'Ser', 'Trp', 'Tyr', 'Pro', 'His', 'Glu', 'Gln', 'Asp', 'Asn', 'Lys', 'Arg']\n",
    "for x in aa:\n",
    "    for y in aa:\n",
    "        if x+y not in p:\n",
    "            p[x+y] = 0\n",
    "        if x+y not in b:\n",
    "            b[x+y] = 0\n",
    "        print(\"{}\\t{}\\t{}\".format(x+y,p[x+y],b[x+y]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "beT4z2lvLE_h"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f3e23687f6db689031a4c6ac8d1dd18220815c76a7a8fef3590edc5a74f2121"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
